{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text preparation\n",
    "\n",
    "As our rap lyrics contains many typos, we have looked closely and discovered a lot of new contractions in rap.\n",
    "Since rap words are often abbreviated, a lot of the rap words are not recognized by a standard dictionary (\"cuz\" is not a word)\n",
    "\n",
    "If we don't consider these abbreviations, our later used autocorrection using edits might incorrectly infer\n",
    "\n",
    "**cuz &rarr; cut**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tools.processing as pre\n",
    "text = pre.get_text(\"data/cleaned-rap-lyrics/cleankid_cudi.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Removing extra spacing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jones ; we born to die for real ; so i get high just like i am born to fly to the moon ; i am in the court with marijuana eyes sorry judge ; we hit the clubs until the morning rise cause of last night ; cause day and night day and night ; we run the streets hope i do not pay that price pray for me ; they got the nerve to tell me press my brakes what ; and if i do then how will rent get paid paid ; so now i am thinkin that what is your thought ; two hundred stacks what would it bring me back thinkin to flip ; especially now that recessions here it is hard out here ; my only answers to my questions is is let me figure out ; ok now here 's a thought one more thought ; streets is a marriage that you can not divorce ; life is a bitch but i think i fell in love i love that bitch ; so i treat the game just like i am sellin drugs drugs ; because day and night ; the lonely stoner seem to free his mind at night ; he is all alone through the day and night ; the lonely loner seem to free his mind \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "remove_lbreak = text.replace(\"\\n\", \" ; \")\n",
    "remove_space  = re.sub(\" +\", \" \", remove_lbreak)\n",
    "\n",
    "print(expanded[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Expand Contractions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTRACTION_MAP = {\"'em\":\"them\",\"y'know\": \"you know\", \"'hem\": \"them\",                   \n",
    "                   \"c'mon\": \"come on\", \"'caine\": \"cocaine\",\n",
    "                   \"mo'\": \"my\", \"cha'\": \"ya\", \"'cha\": \"ya\",\n",
    "                   \"whaddya\": \"what do ya\", \"nuttin\": \"nothing\",\n",
    "                   \"thru\": \"through\", \"shoulda\": \"should have\",\n",
    "                   \"lets\": \"let us\", \"let's\": \"let us\", \"f'real\": \"for real\",\n",
    "                   \"'til\": \"until\", \"i'ma\": \"i am going to\",\n",
    "                   \"ima\": \"i am going to\", \"'cross\": \"across\",\n",
    "                   \" imma \": \"i am going to\", \"tho'\": \"though\",\n",
    "                   \"st8\": \"straight\", \"til'\": \"until\", \"str8\": \"straight\",\n",
    "                   \"'sll \": \"s will\", \"withcha\": \"with ya\", \"befo'\": \"before\",\n",
    "                   \"cuz'\": \"because\",\"coz'\": \"because\",\"cuz'\": \"because\",\"cuz\": \"because\",\n",
    "                   \"coz\": \"because\",\"'im\": \"him\", \"'bout\": \"about\",\"tha'\": \"the\",\"tu'\": \"to\",\"'n'\": \"and\",\n",
    "                   \" n \": \" and \", \"'n\": \"and\", \"yo'\": \"your\", \"witcha\": \"with ya\", \"wit'\": \"with\",\n",
    "                   \"whaddup\": \"what is up\", \"pro'lly\": \"probably\", \"prolly\": \"probably\", \n",
    "                   \"'laxin\": \"relaxing\", \"tryna\": \"trying to\", \"'tack\": \"attack\",\n",
    "                   \"'head\": \"ahead\", \"lil'\": \"little\", \"getcha\": \"get ya\",\n",
    "                   \"wit'chu\": \"with you\", \"get'cha\": \"get ya\",\"gon\": \"going to\",\n",
    "                   \"sweatcha\": \"sweat ya\", \"e'ry\": \"every\", \"what'cha\": \"what ya\",\n",
    "                   \" aight \": \" all right \", \"hitcha\": \"hit ya\", \"hit'cha\": \"hit ya\",\n",
    "                   \"gov'na\": \"governor\", \"'fore\": \"before\", \"mill'\": \"million\",\n",
    "                   \"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"can not\", \n",
    "                   \"can't've\": \"can not have\", \"'cause\": \"because\", \"could've\": \"could have\", \n",
    "                   \"couldn't\": \"could not\", \"couldn't've\": \"could not have\",\"didn't\": \"did not\", \n",
    "                   \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \n",
    "                   \"hadn't've\": \"had not have\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \n",
    "                   \"he'd\": \"he would\", \"he'd've\": \"he would have\", \"he'll\": \"he will\", \n",
    "                   \"he'll've\": \"he he will have\", \"he's\": \"he is\", \"how'd\": \"how did\", \n",
    "                   \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\", \n",
    "                   \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\",\n",
    "                   \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \n",
    "                   \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\", \n",
    "                   \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \n",
    "                   \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \n",
    "                   \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \n",
    "                   \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \n",
    "                   \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \n",
    "                   \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \n",
    "                   \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \n",
    "                   \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\",\n",
    "                   \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \n",
    "                   \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \n",
    "                   \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \n",
    "                   \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \n",
    "                   \"this's\": \"this is\",\n",
    "                   \"that'd\": \"that would\", \"that'd've\": \"that would have\",\"that's\": \"that is\", \n",
    "                   \"there'd\": \"there would\", \"there'd've\": \"there would have\",\"there's\": \"there is\", \n",
    "                   \"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \n",
    "                   \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \n",
    "                   \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \n",
    "                   \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \n",
    "                   \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \n",
    "                   \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\", \n",
    "                   \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \n",
    "                   \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \n",
    "                   \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \n",
    "                   \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why'd\": \"why did\",\n",
    "                   \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \n",
    "                   \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \n",
    "                   \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\n",
    "                   \"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                   \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \n",
    "                   \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\", \n",
    "                   \"gon'\": \"going to\",\n",
    "                   \" an'\": \"and\", \"yall\": \"ya all\", \"youre\": \"you are\",\n",
    "                   \" de \": \" the \", \"en'\": \"ing\",\n",
    "                   \"in'\": \"ing\", \"'ll\": \" will\", \"'ve\": \" have\", \" u \": \" you \", \n",
    "                   \"mutha\": \"mother\", \"brotha\": \"brother\", \"2pac\": \"tupac\", \" nite\": \" night\"\n",
    "                  } \n",
    "\n",
    "def expand_contractions(sentence, contraction_mapping):\n",
    "    contractions_pattern = re.compile('({})'.format('|'.join(contraction_mapping.keys())), \n",
    "                                      flags=re.IGNORECASE|re.DOTALL)\n",
    "    def expand_match(contraction):\n",
    "        match = contraction.group(0)\n",
    "        first_char = match[0]\n",
    "        expanded_contraction = contraction_mapping.get(match)\n",
    "        return expanded_contraction\n",
    "        \n",
    "    expanded_sentence = contractions_pattern.sub(expand_match, sentence)\n",
    "    return expanded_sentence\n",
    "\n",
    "\n",
    "expanded = expand_contractions(remove_space, CONTRACTION_MAP)\n",
    "\n",
    "# some contractions cannot be fixed so easily\n",
    "# example: Tom's bag is outside VS Tom's outside\n",
    "expanded = expanded.replace(\"'s \", \" 's \")\n",
    "expanded = expanded.replace(\"s'\", \" 's \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'you are going down i will and utop fucking tell the dad have dey sleeping'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expand_contractions(\"youre going down i'll n utop fucken' tell de dad've dey sleepin'\", CONTRACTION_MAP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Correcting Typos using our new dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 7374),\n",
       " ('i', 6883),\n",
       " ('is', 4549),\n",
       " ('to', 3975),\n",
       " ('a', 3757),\n",
       " ('you', 3692),\n",
       " ('and', 3649),\n",
       " ('it', 3028),\n",
       " ('my', 2385),\n",
       " ('me', 2371),\n",
       " ('not', 2306),\n",
       " ('in', 2069),\n",
       " ('am', 1913),\n",
       " ('of', 1574),\n",
       " ('that', 1506),\n",
       " ('on', 1451),\n",
       " ('for', 1324),\n",
       " ('nigga', 1231),\n",
       " ('like', 1219),\n",
       " ('we', 1187)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import collections\n",
    "\n",
    "def tokens(text):\n",
    "    \"\"\"\n",
    "    Get all words from corpus\n",
    "    \"\"\"\n",
    "    return re.findall(r'\\w+', text.lower())\n",
    "\n",
    "wordlist = pre.get_text('data/ref_text2.txt')\n",
    "\n",
    "WORDS = tokens(wordlist) + [\";\"]\n",
    "WORD_COUNTS = collections.Counter(WORDS)\n",
    "\n",
    "WORD_COUNTS.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knowing\n"
     ]
    }
   ],
   "source": [
    "def edits0(word):\n",
    "    \"\"\"\n",
    "    Return all strings that are zero edits away (i.e. the word itself).\n",
    "    \"\"\"\n",
    "    return{word}\n",
    "\n",
    "def edits1(word):\n",
    "    \"\"\"\n",
    "    Return all strings that are one edits away.\n",
    "    \"\"\"\n",
    "    alphabet = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    def splits(word):\n",
    "        \"\"\"\n",
    "        return a list of all possible pairs\n",
    "        that the input word is made of\n",
    "        \"\"\"\n",
    "        return [(word[:i], word[i:]) for i in range(len(word)+1)]\n",
    "    pairs = splits(word)\n",
    "    deletes = [a+b[1:] for (a,b) in pairs if b]\n",
    "    transposes = [a+b[1]+b[0]+b[2:] for (a,b) in pairs if len(b) >1]\n",
    "    replaces = [a+c+b[1:] for (a,b) in pairs for c in alphabet if b]\n",
    "    inserts = [a+c+b for (a,b) in pairs for c in alphabet]\n",
    "    return(set(deletes + transposes + replaces + inserts))\n",
    "\n",
    "def edits2(word):\n",
    "    \"\"\"\n",
    "    return all strings that are two edits away.\n",
    "    \"\"\"\n",
    "    return {e2 for e1 in edits1(word) for e2 in edits1(e1)}\n",
    "\n",
    "def known(words):\n",
    "    return {w for w in words if w in WORD_COUNTS}\n",
    "\n",
    "unk = []\n",
    "def correct(word):\n",
    "    candidates = (known(edits0(word)) or\n",
    "                 known(edits1(word)) or\n",
    "                 known(edits2(word)) or\n",
    "                 [word])\n",
    "    cand = max(candidates, key=WORD_COUNTS.get)\n",
    "    if(candidates == known(edits2(word))):\n",
    "        if(cand != word):\n",
    "            unk.append(word)\n",
    "    return cand\n",
    "\n",
    "def correct_text(text):\n",
    "    processed = text.replace('\\n', ' \\n ')\n",
    "    corrected = [ correct(word) for word in processed.split(\" \") ]\n",
    "    \n",
    "    return \" \".join(corrected)\n",
    "    \n",
    "print (correct(\"knowin\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jones ; we born to die for real ; so i get high just like i '"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expanded[:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected = correct_text(expanded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'scantron', 'withcha', \"befo'\", 'awww', '123', '10', 'surelyi', 'shinnin', 'somthin', \"'88\", 'togined', 'rrright', 'electric', 'coastses', 'togine', 'marriage', '501', 'wizardry', 'ayyy'}\n"
     ]
    }
   ],
   "source": [
    "# print( f\"number of unknown words: {len(unk)}\")\n",
    "print(set(unk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in set(unk):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add all corrected unknowns to the reference text and rerun the correction process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tools.processing as pre\n",
    "\n",
    "def recorrect(word):\n",
    "    candidates = (known(edits0(word)) or\n",
    "                 known(edits1(word)) or\n",
    "                 known(edits2(word)) or\n",
    "                 [word])\n",
    "    return max(candidates, key=WORD_COUNTS.get)\n",
    "\n",
    "def recorrect_text(text):\n",
    "    processed = text.replace('\\n', ' \\n ')\n",
    "    corrected = [ recorrect(word) for word in processed.split(\" \") ]\n",
    "    \n",
    "    return \" \".join(corrected)\n",
    "\n",
    "wordlist = pre.get_text('data/ref_text3.txt')\n",
    "\n",
    "corrected = recorrect_text(expanded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jones ; we born to die for real ; so i get high just like i am born to fly to the moon ; i am in the court with marijuana eyes sorry judge ; we hit the clubs until the morning rise cause of last night ; cause day and night day and night ; we run the streets hope i do not pay that price pray for me ; they got the nerve to tell me press my brakes what ; and if i do then how will rent get paid paid ; so now i am thinking that what is your thought ; two hundred stacks what would it bring me back thi'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrected[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['88', '23', '23', '08', '09', '50', '88', '99', '30', '23', '23', '88', '23', '50', '22', '24', '92', '99', '22', '88']\n"
     ]
    }
   ],
   "source": [
    "words = corrected.split(\" \")\n",
    "numbers_str = filter( lambda word: word.isnumeric(), words )\n",
    "print(list(numbers_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['88', '23', '23', '08', '09', '50', '88', '99', '6th', '30', '23', '23', '25th', '88', '23', '50', '22', '24', '92', '99', '22', '88']\n"
     ]
    }
   ],
   "source": [
    "print(re.findall(r\"\\w*[0-9]+\\w*\", corrected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected = corrected.replace(\"18th\", \"eighteenth\")\n",
    "corrected = corrected.replace(\"56ths\", \"eighteenth\")\n",
    "corrected = corrected.replace(\"110th\", \"hundred and tenth\")\n",
    "corrected = corrected.replace(\"25th\", \"twenty fifth\")\n",
    "corrected = corrected.replace(\"5th\", \"fifth\")\n",
    "corrected = corrected.replace(\"4th\", \"fourth\")\n",
    "corrected = corrected.replace(\"6th\", \"sixth\")\n",
    "corrected = corrected.replace(\"3d\", \"three dee\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fifty five nine one one\n"
     ]
    }
   ],
   "source": [
    "import inflect\n",
    "\n",
    "def number_to_word(number_str):\n",
    "    \n",
    "    p = inflect.engine()\n",
    "    \n",
    "    if   (len(number_str) <= 2):\n",
    "        number = p.number_to_words(int(number_str))\n",
    "        if(number == \"zero\"):\n",
    "            return \"ou\"\n",
    "        else: \n",
    "            return number.replace(\"-\",\" \")\n",
    "    \n",
    "    elif (len(number_str) == 4):\n",
    "        digit_1 = int( number_str[:2] )\n",
    "        digit_2 = int( number_str[2:] )\n",
    "        number = p.number_to_words(digit_1) + \" \" + p.number_to_words(digit_2)\n",
    "        if(int(number_str[2:]) < 10):\n",
    "            return p.number_to_words(int(number_str)).replace(\",\", \"\")\n",
    "        return number.replace(\"-\", \" \")\n",
    "        \n",
    "    else:\n",
    "        val = \" \".join( [p.number_to_words(int(digit)) for digit in number_str] )\n",
    "        return val.replace(\"zero\", \"ou\")\n",
    "\n",
    "print( number_to_word(\"55\"), number_to_word(\"911\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'92': 'ninety two',\n",
       " '08': 'eight',\n",
       " '99': 'ninety nine',\n",
       " '30': 'thirty',\n",
       " '23': 'twenty three',\n",
       " '22': 'twenty two',\n",
       " '88': 'eighty eight',\n",
       " '50': 'fifty',\n",
       " '24': 'twenty four',\n",
       " '09': 'nine'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_number_mapping( text ):\n",
    "    words = text.split(\" \")\n",
    "    numbers_str = filter( lambda word: word.isnumeric(), words )\n",
    "    \n",
    "    mapping = {}\n",
    "    for number in set(numbers_str):\n",
    "        mapping[number] = number_to_word(number)\n",
    "    return mapping\n",
    "\n",
    "encoding = get_number_mapping(corrected)\n",
    "encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jones ; we born to die for real ; so i get high just like i am born to fly to the moon ; i am in the court with marijuana eyes sorry judge ; we hit the clubs until the morning rise cause of last night ; cause day and night day and night ; we run the streets hope i do not pay that price pray for me ; they got the nerve to tell me press my brakes what ; and if i do then how will rent get paid paid ; so now i am thinking that what is your thought ; two hundred stacks what would it bring me back thi\n"
     ]
    }
   ],
   "source": [
    "def encode_numbers(text, encoding):\n",
    "    encoded = text\n",
    "    \n",
    "    items = list( encoding.items() )\n",
    "    items.sort(key=lambda item: len( item[0]), reverse=True)\n",
    "    \n",
    "    for number, substitute in items:\n",
    "        encoded = encoded.replace(number, substitute)\n",
    "    return encoded\n",
    "\n",
    "number_encoded = encode_numbers(corrected, encoding)\n",
    "               \n",
    "print( number_encoded[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre.write_text(\"data/prepped/cleankid_cudi.txt\", number_encoded )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
