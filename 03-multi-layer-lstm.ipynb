{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 - Multi Layer Network\n",
    "\n",
    "In this notebook we try stacking multiple hidden layer inside our rnn cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['as', 'real', 'as', 'it', 'seems', 'the', 'american', 'dream', '\\\\n', \"ain't\"], 'nothing'), (['real', 'as', 'it', 'seems', 'the', 'american', 'dream', '\\\\n', \"ain't\", 'nothing'], 'but'), (['as', 'it', 'seems', 'the', 'american', 'dream', '\\\\n', \"ain't\", 'nothing', 'but'], 'another'), (['it', 'seems', 'the', 'american', 'dream', '\\\\n', \"ain't\", 'nothing', 'but', 'another'], 'calculated'), (['seems', 'the', 'american', 'dream', '\\\\n', \"ain't\", 'nothing', 'but', 'another', 'calculated'], 'schemes')]\n"
     ]
    }
   ],
   "source": [
    "import tools.processing as pre\n",
    "import re\n",
    "\n",
    "# use less text for now to avoid memory error\n",
    "text = pre.get_text(\"data/cleaned-rap-lyrics/clean2_pac_.txt\")\n",
    "vocab = pre.Vocabulary(text)\n",
    "# double \\\\n to avoid null error in tensorboard projection\n",
    "text = text.replace(\"\\n\", \" \\\\n \")\n",
    "# remove extra spacing\n",
    "tokens = re.sub( \" +\", \" \", text).split(\" \")[:-1]\n",
    "\n",
    "TIMESTEPS = 10\n",
    "\n",
    "str_data, str_labels = pre.create_data_label_pairs(tokens, TIMESTEPS)\n",
    "\n",
    "print( list( zip(str_data, str_labels) )[:5] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tools.training as tr\n",
    "\n",
    "encoder = tr.OneHotWordEncoder(\"1-Hot-Word-Encoding\", vocab.word2index)\n",
    "decoder = tr.OneHotWordDecoder(\"1-Hot-Word-Decoding\", vocab.index2word, temperature=0.8)\n",
    "\n",
    "data = encoder.encode( str_data )\n",
    "labels = encoder.encode_labels( str_labels )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tools.architectures as nn\n",
    "\n",
    "class SimpleMultiLayerRNN(nn.Trainable):\n",
    "    def __init__(self, name):\n",
    "        super().__init__(name)\n",
    "\n",
    "    def build(self, num_layers, hidden_layer_size, vocab_size, time_steps, l2_reg=0.0):\n",
    "        self.time_steps = time_steps\n",
    "        self.vocab_size = vocab_size\n",
    "\n",
    "        self.X = tf.placeholder(tf.float32, shape=[None, time_steps, vocab_size], name=\"data\")\n",
    "        self.Y = tf.placeholder(tf.int16, shape=[None, vocab_size], name=\"labels\")\n",
    "\n",
    "        self.X = tf.placeholder(tf.float32, shape=[None, time_steps, vocab_size], name=\"data\")\n",
    "        \n",
    "        with tf.variable_scope(self.name, reuse=tf.AUTO_REUSE):\n",
    "\n",
    "            self.stacked_cells = lstm_layer(num_layers, hidden_layer_size)\n",
    "\n",
    "            self.outputs, self.states = tf.nn.dynamic_rnn(\n",
    "                    self.stacked_cells, self.X, dtype=tf.float32)\n",
    "            \n",
    "            self.last_rnn_output = self.states[num_layers - 1][1]\n",
    "\n",
    "            self.final_output, W_out, b_out = full_layer(self.last_rnn_output, vocab_size)\n",
    "\n",
    "            self.weights.append(W_out)\n",
    "            self.biases.append(b_out)\n",
    "\n",
    "            self.softmax = tf.nn.softmax_cross_entropy_with_logits_v2(logits=self.final_output,\n",
    "                    labels=self.Y)\n",
    "            self.cross_entropy_loss = tf.reduce_mean(self.softmax)\n",
    "\n",
    "            self.loss = self.cross_entropy_loss\n",
    "\n",
    "            self.optimizer = tf.train.AdamOptimizer()\n",
    "            self.train_step= self.optimizer.minimize(self.loss)\n",
    "\n",
    "            self.correct_prediction = tf.equal(tf.argmax(self.Y,1), tf.argmax(self.final_output, 1))\n",
    "            self.accuracy = tf.reduce_mean(tf.cast(self.correct_prediction, tf.float32))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch 1/20\n",
      "Loss:    \t 5.8571906089782715\n",
      "Accuracy:\t 11.005839347839355\n",
      "------Sampling----------\n",
      "seed: \tas real as it seems the american dream\n",
      "ain't nothing but another calculated schemes\n",
      "to get us locked up\n",
      "result:as real as it seems the american dream\n",
      "ain't nothing but another calculated schemes\n",
      "to get us locked up \n",
      " the the in the they you \n",
      " the \n",
      " \n",
      " ears my boldy ain't outro \n",
      " the wheel \n",
      "\n",
      "\n",
      "\n",
      "Epoch 2/20\n",
      "Loss:    \t 5.772158145904541\n",
      "Accuracy:\t 11.005839347839355\n",
      "------Sampling----------\n",
      "seed: \tas real as it seems the american dream\n",
      "ain't nothing but another calculated schemes\n",
      "to get us locked up\n",
      "result:as real as it seems the american dream\n",
      "ain't nothing but another calculated schemes\n",
      "to get us locked up \n",
      " and \n",
      " motts time just shocks do while smokin' me \n",
      " \n",
      " i'm could love of knew block needin'\n",
      "\n",
      "\n",
      "Epoch 3/20\n",
      "Loss:    \t 5.70475959777832\n",
      "Accuracy:\t 11.005839347839355\n",
      "------Sampling----------\n",
      "seed: \tas real as it seems the american dream\n",
      "ain't nothing but another calculated schemes\n",
      "to get us locked up\n",
      "result:as real as it seems the american dream\n",
      "ain't nothing but another calculated schemes\n",
      "to get us locked up i'm but \n",
      " ya if you \n",
      " like up know \n",
      " huh had a can a liberty but damn was\n",
      "\n",
      "\n",
      "Epoch 4/20\n",
      "Loss:    \t 5.7194437980651855\n",
      "Accuracy:\t 11.005839347839355\n",
      "------Sampling----------\n",
      "seed: \tas real as it seems the american dream\n",
      "ain't nothing but another calculated schemes\n",
      "to get us locked up\n",
      "result:as real as it seems the american dream\n",
      "ain't nothing but another calculated schemes\n",
      "to get us locked up up \n",
      " with \n",
      " is \n",
      " beat pissed money breath on \n",
      " \n",
      " to \n",
      " for \n",
      " your do my\n",
      "\n",
      "\n",
      "Epoch 5/20\n",
      "Loss:    \t 5.643709182739258\n",
      "Accuracy:\t 11.821085929870605\n",
      "------Sampling----------\n",
      "seed: \tas real as it seems the american dream\n",
      "ain't nothing but another calculated schemes\n",
      "to get us locked up\n",
      "result:as real as it seems the american dream\n",
      "ain't nothing but another calculated schemes\n",
      "to get us locked up \n",
      " understand so \n",
      " stopped my dope paniced dope the the \n",
      " big won't and keep bad \n",
      " it justice\n",
      "\n",
      "\n",
      "Epoch 6/20\n",
      "Loss:    \t 5.5245280265808105\n",
      "Accuracy:\t 13.649884223937988\n",
      "------Sampling----------\n",
      "seed: \tas real as it seems the american dream\n",
      "ain't nothing but another calculated schemes\n",
      "to get us locked up\n",
      "result:as real as it seems the american dream\n",
      "ain't nothing but another calculated schemes\n",
      "to get us locked up took never i battlin' get i started \n",
      " \n",
      " mystery a offthan a em' like so the i minnie room\n",
      "\n",
      "\n",
      "Epoch 7/20\n",
      "Loss:    \t 5.427427291870117\n",
      "Accuracy:\t 14.112591743469238\n",
      "------Sampling----------\n",
      "seed: \tas real as it seems the american dream\n",
      "ain't nothing but another calculated schemes\n",
      "to get us locked up\n",
      "result:as real as it seems the american dream\n",
      "ain't nothing but another calculated schemes\n",
      "to get us locked up as the rather \n",
      " mouth real to real to \n",
      " my my you hit a a passed \n",
      " on or\n",
      "\n",
      "\n",
      "Epoch 8/20\n",
      "Loss:    \t 5.414429187774658\n",
      "Accuracy:\t 11.600749015808105\n",
      "------Sampling----------\n",
      "seed: \tas real as it seems the american dream\n",
      "ain't nothing but another calculated schemes\n",
      "to get us locked up\n",
      "result:as real as it seems the american dream\n",
      "ain't nothing but another calculated schemes\n",
      "to get us locked up in what i to now this with monday pull i'm and that \n",
      " a a shot get a her my\n",
      "\n",
      "\n",
      "Epoch 9/20\n",
      "Loss:    \t 5.218966960906982\n",
      "Accuracy:\t 15.37952995300293\n",
      "------Sampling----------\n",
      "seed: \tas real as it seems the american dream\n",
      "ain't nothing but another calculated schemes\n",
      "to get us locked up\n",
      "result:as real as it seems the american dream\n",
      "ain't nothing but another calculated schemes\n",
      "to get us locked up up \n",
      " makin' when can the he i steppin' let a up that i i \n",
      " \n",
      " my ya if\n",
      "\n",
      "\n",
      "Epoch 10/20\n",
      "Loss:    \t 5.116966247558594\n",
      "Accuracy:\t 16.271896362304688\n",
      "------Sampling----------\n",
      "seed: \tas real as it seems the american dream\n",
      "ain't nothing but another calculated schemes\n",
      "to get us locked up\n",
      "result:as real as it seems the american dream\n",
      "ain't nothing but another calculated schemes\n",
      "to get us locked up time he he history the rhyme city to them delusion hell the static never now her ya i quick good's\n",
      "\n",
      "\n",
      "Epoch 11/20\n",
      "Loss:    \t 4.805177211761475\n",
      "Accuracy:\t 16.987991333007812\n",
      "------Sampling----------\n",
      "seed: \tas real as it seems the american dream\n",
      "ain't nothing but another calculated schemes\n",
      "to get us locked up\n",
      "result:as real as it seems the american dream\n",
      "ain't nothing but another calculated schemes\n",
      "to get us locked up a why to got to to to \n",
      " he when my a to to \n",
      " the to chains \n",
      " in\n",
      "\n",
      "\n",
      "Epoch 12/20\n",
      "Loss:    \t 4.498571395874023\n",
      "Accuracy:\t 19.962543487548828\n",
      "------Sampling----------\n",
      "seed: \tas real as it seems the american dream\n",
      "ain't nothing but another calculated schemes\n",
      "to get us locked up\n",
      "result:as real as it seems the american dream\n",
      "ain't nothing but another calculated schemes\n",
      "to get us locked up the a at to by \n",
      " toe risin the nigga play with \n",
      " along time i fell in the \n",
      "\n",
      "\n",
      "\n",
      "Epoch 13/20\n",
      "Loss:    \t 4.277435302734375\n",
      "Accuracy:\t 21.064228057861328\n",
      "------Sampling----------\n",
      "seed: \tas real as it seems the american dream\n",
      "ain't nothing but another calculated schemes\n",
      "to get us locked up\n",
      "result:as real as it seems the american dream\n",
      "ain't nothing but another calculated schemes\n",
      "to get us locked up shot into baby little to \n",
      " to all introduction you're a rather \n",
      " government \n",
      " slaves as send illtrip rock\n",
      "\n",
      "\n",
      "Epoch 14/20\n",
      "Loss:    \t 3.881801128387451\n",
      "Accuracy:\t 24.77690887451172\n",
      "------Sampling----------\n",
      "seed: \tas real as it seems the american dream\n",
      "ain't nothing but another calculated schemes\n",
      "to get us locked up\n",
      "result:as real as it seems the american dream\n",
      "ain't nothing but another calculated schemes\n",
      "to get us locked up to shot it control \n",
      " to to of to god lot me \n",
      " out all that all can baby a\n",
      "\n",
      "\n",
      "Epoch 15/20\n",
      "Loss:    \t 3.7189788818359375\n",
      "Accuracy:\t 26.16503143310547\n",
      "------Sampling----------\n",
      "seed: \tas real as it seems the american dream\n",
      "ain't nothing but another calculated schemes\n",
      "to get us locked up\n",
      "result:as real as it seems the american dream\n",
      "ain't nothing but another calculated schemes\n",
      "to get us locked up back \n",
      " \n",
      " nothing to gift that wall the \n",
      " \n",
      " \n",
      " got wasn't the the the posse \n",
      " smokin'\n",
      "\n",
      "\n",
      "Epoch 16/20\n",
      "Loss:    \t 3.234036445617676\n",
      "Accuracy:\t 32.951416015625\n",
      "------Sampling----------\n",
      "seed: \tas real as it seems the american dream\n",
      "ain't nothing but another calculated schemes\n",
      "to get us locked up\n",
      "result:as real as it seems the american dream\n",
      "ain't nothing but another calculated schemes\n",
      "to get us locked up up up up in static the try us you your killin pretend me me me tried mail sweatin' leaves \n",
      "\n",
      "\n",
      "\n",
      "Epoch 17/20\n",
      "Loss:    \t 3.096541404724121\n",
      "Accuracy:\t 32.951416015625\n",
      "------Sampling----------\n",
      "seed: \tas real as it seems the american dream\n",
      "ain't nothing but another calculated schemes\n",
      "to get us locked up\n",
      "result:as real as it seems the american dream\n",
      "ain't nothing but another calculated schemes\n",
      "to get us locked up up back back \n",
      " to deny deny the means from man you you was my my stumped tried lets step\n",
      "\n",
      "\n",
      "Epoch 18/20\n",
      "Loss:    \t 2.7989795207977295\n",
      "Accuracy:\t 38.42679214477539\n",
      "------Sampling----------\n",
      "seed: \tas real as it seems the american dream\n",
      "ain't nothing but another calculated schemes\n",
      "to get us locked up\n",
      "result:as real as it seems the american dream\n",
      "ain't nothing but another calculated schemes\n",
      "to get us locked up shot up up in \n",
      " deny to on the monday be shot \n",
      " was to to me barred \n",
      " my\n",
      "\n",
      "\n",
      "Epoch 19/20\n",
      "Loss:    \t 2.469958782196045\n",
      "Accuracy:\t 45.84113693237305\n",
      "------Sampling----------\n",
      "seed: \tas real as it seems the american dream\n",
      "ain't nothing but another calculated schemes\n",
      "to get us locked up\n",
      "result:as real as it seems the american dream\n",
      "ain't nothing but another calculated schemes\n",
      "to get us locked up the back back the just \n",
      " us to by hoes they do \n",
      " power bizzy cha' over \n",
      " moocher of\n",
      "\n",
      "\n",
      "Epoch 20/20\n",
      "Loss:    \t 2.5058913230895996\n",
      "Accuracy:\t 43.70386505126953\n",
      "------Sampling----------\n",
      "seed: \tas real as it seems the american dream\n",
      "ain't nothing but another calculated schemes\n",
      "to get us locked up\n",
      "result:as real as it seems the american dream\n",
      "ain't nothing but another calculated schemes\n",
      "to get us locked up started up back in \n",
      " deny sneak to hiphop future future crazy \n",
      " burnin but for deadly of niggaz the\n"
     ]
    }
   ],
   "source": [
    "import tools.processing as pre\n",
    "import tools.architectures as nn\n",
    "\n",
    "NUM_LAYERS = 2\n",
    "HIDDEN_LAYER_SIZE = 512\n",
    "VOCAB_SIZE = vocab.get_size()\n",
    "TIMESTEPS = 10\n",
    "\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "rnn = SimpleMultiLayerRNN(name = \"multi-pac\")\n",
    "rnn.build(NUM_LAYERS, HIDDEN_LAYER_SIZE, VOCAB_SIZE, TIMESTEPS, l2_reg=0.0)\n",
    "\n",
    "sampler = lambda trainable, seed_text: tr.sample( seed_text, trainable, encoder, decoder, length=20)\n",
    "\n",
    "tr.train_model(rnn, data, labels, sampler, epochs=EPOCHS, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Sampling----------\n",
      "seed: \tlet us work things out with a shot \n",
      " go take the man\n",
      "result:let us work things out with a shot \n",
      " go take the man shit hand \n",
      " hate they they get gettin' dirty \n",
      " they i got and so his \n",
      " know get rockin' the shit static stole \n",
      " come come and they windows really and \n",
      " come \n",
      " whiff do in this to come come \n",
      " they come come come come come come\n"
     ]
    }
   ],
   "source": [
    "decoder.temperature = 0.7\n",
    "\n",
    "sampler = lambda trainable, seed_text: tr.sample( seed_text, trainable, encoder, decoder, length=50)\n",
    "sampler(rnn, \"i g\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem\n",
    "\n",
    "How can we work out proper features from the text?\n",
    "\n",
    "Just because a line does not match 100% with the original one that doesn't mean that it is bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1093"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab._dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
