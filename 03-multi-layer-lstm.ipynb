{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 - Multi Layer Network\n",
    "\n",
    "In this notebook we try stacking multiple hidden layer inside our rnn cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['as', 'real', 'as', 'it', 'seems', 'the', 'american', 'dream', '\\\\n', \"ain't\", 'nothing', 'but', 'another', 'calculated', 'schemes', '\\\\n'], 'to'), (['real', 'as', 'it', 'seems', 'the', 'american', 'dream', '\\\\n', \"ain't\", 'nothing', 'but', 'another', 'calculated', 'schemes', '\\\\n', 'to'], 'get'), (['as', 'it', 'seems', 'the', 'american', 'dream', '\\\\n', \"ain't\", 'nothing', 'but', 'another', 'calculated', 'schemes', '\\\\n', 'to', 'get'], 'us'), (['it', 'seems', 'the', 'american', 'dream', '\\\\n', \"ain't\", 'nothing', 'but', 'another', 'calculated', 'schemes', '\\\\n', 'to', 'get', 'us'], 'locked'), (['seems', 'the', 'american', 'dream', '\\\\n', \"ain't\", 'nothing', 'but', 'another', 'calculated', 'schemes', '\\\\n', 'to', 'get', 'us', 'locked'], 'up')]\n"
     ]
    }
   ],
   "source": [
    "import tools.processing as pre\n",
    "import re\n",
    "\n",
    "# use less text for now to avoid memory error\n",
    "text = pre.get_text(\"data/cleaned-rap-lyrics/clean2_pac_.txt\")\n",
    "vocab = pre.Vocabulary(text)\n",
    "# double \\\\n to avoid null error in tensorboard projection\n",
    "text = text.replace(\"\\n\", \" \\\\n \")\n",
    "# remove extra spacing\n",
    "tokens = re.sub( \" +\", \" \", text).split(\" \")[:-1]\n",
    "\n",
    "TIMESTEPS = 16\n",
    "\n",
    "str_data, str_labels = pre.create_data_label_pairs(tokens, TIMESTEPS)\n",
    "\n",
    "print( list( zip(str_data, str_labels) )[:5] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tools.training as tr\n",
    "\n",
    "encoder = tr.OneHotWordEncoder(\"1-Hot-Word-Encoding\", vocab.word2index)\n",
    "decoder = tr.OneHotWordDecoder(\"1-Hot-Word-Decoding\", vocab.index2word, temperature=0.8)\n",
    "\n",
    "data = encoder.encode( str_data )\n",
    "labels = encoder.encode_labels( str_labels )\n",
    "\n",
    "del str_labels\n",
    "del str_data\n",
    "del tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tools.architectures as nn\n",
    "import tensorflow as tf\n",
    "\n",
    "class SimpleMultiLayerRNN(nn.Trainable):\n",
    "    def __init__(self, name):\n",
    "        super().__init__(name)\n",
    "\n",
    "    def build(self, num_layers, hidden_layer_size, vocab_size, time_steps, l2_reg=0.0):\n",
    "        self.time_steps = time_steps\n",
    "        self.vocab_size = vocab_size\n",
    "\n",
    "        self.X = tf.placeholder(tf.float32, shape=[None, time_steps, vocab_size], name=\"data\")\n",
    "        self.Y = tf.placeholder(tf.int16, shape=[None, vocab_size], name=\"labels\")\n",
    "\n",
    "        self.X = tf.placeholder(tf.float32, shape=[None, time_steps, vocab_size], name=\"data\")\n",
    "        \n",
    "        with tf.variable_scope(self.name, reuse=tf.AUTO_REUSE):\n",
    "\n",
    "            self.stacked_cells = nn.lstm_layer(num_layers, hidden_layer_size)\n",
    "\n",
    "            self.outputs, self.states = tf.nn.dynamic_rnn(\n",
    "                    self.stacked_cells, self.X, dtype=tf.float32)\n",
    "            \n",
    "            self.last_rnn_output = self.states[num_layers - 1][1]\n",
    "\n",
    "            self.final_output, W_out, b_out = nn.full_layer(self.last_rnn_output, vocab_size)\n",
    "\n",
    "            self.weights.append(W_out)\n",
    "            self.biases.append(b_out)\n",
    "\n",
    "            self.softmax = tf.nn.softmax_cross_entropy_with_logits_v2(logits=self.final_output,\n",
    "                    labels=self.Y)\n",
    "            self.cross_entropy_loss = tf.reduce_mean(self.softmax)\n",
    "\n",
    "            self.loss = self.cross_entropy_loss\n",
    "\n",
    "            self.optimizer = tf.train.AdamOptimizer()\n",
    "            self.train_step= self.optimizer.minimize(self.loss)\n",
    "\n",
    "            self.correct_prediction = tf.equal(tf.argmax(self.Y,1), tf.argmax(self.final_output, 1))\n",
    "            self.accuracy = tf.reduce_mean(tf.cast(self.correct_prediction, tf.float32))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch 1/20\n",
      "Loss:    \t 5.954540252685547\n",
      "Accuracy:\t 10.942182540893555\n",
      "------Sampling----------\n",
      "seed: \tas real as it seems the american dream\n",
      "ain't nothing but another calculated schemes\n",
      "to get us locked up\n",
      "result:as real as it seems the american dream\n",
      "ain't nothing but another calculated schemes\n",
      "to get us locked up patio \n",
      " its or of life \n",
      " \n",
      " and told it fight \n",
      " what now a \n",
      " \n",
      " stand my\n",
      "\n",
      "\n",
      "Epoch 2/20\n",
      "Loss:    \t 5.896312713623047\n",
      "Accuracy:\t 10.9348726272583\n",
      "------Sampling----------\n",
      "seed: \tas real as it seems the american dream\n",
      "ain't nothing but another calculated schemes\n",
      "to get us locked up\n",
      "result:as real as it seems the american dream\n",
      "ain't nothing but another calculated schemes\n",
      "to get us locked up brothers \n",
      " \n",
      " the the played \n",
      " a static rolled way me so the want a \n",
      " a the hard\n",
      "\n",
      "\n",
      "Epoch 3/20\n",
      "Loss:    \t 5.876816272735596\n",
      "Accuracy:\t 10.942182540893555\n",
      "------Sampling----------\n",
      "seed: \tas real as it seems the american dream\n",
      "ain't nothing but another calculated schemes\n",
      "to get us locked up\n",
      "result:as real as it seems the american dream\n",
      "ain't nothing but another calculated schemes\n",
      "to get us locked up \n",
      " but \n",
      " moved \n",
      " \n",
      " talking the daily cause \n",
      " but all lot really who the \n",
      " peace stretch\n",
      "\n",
      "\n",
      "Epoch 4/20\n",
      "Loss:    \t 5.847941875457764\n",
      "Accuracy:\t 10.942182540893555\n",
      "------Sampling----------\n",
      "seed: \tas real as it seems the american dream\n",
      "ain't nothing but another calculated schemes\n",
      "to get us locked up\n",
      "result:as real as it seems the american dream\n",
      "ain't nothing but another calculated schemes\n",
      "to get us locked up getting words health with none the \n",
      " let the cause running and all comin this and \n",
      " the chose act\n",
      "\n",
      "\n",
      "Epoch 5/20\n",
      "Loss:    \t 5.747490406036377\n",
      "Accuracy:\t 12.184782028198242\n",
      "------Sampling----------\n",
      "seed: \tas real as it seems the american dream\n",
      "ain't nothing but another calculated schemes\n",
      "to get us locked up\n",
      "result:as real as it seems the american dream\n",
      "ain't nothing but another calculated schemes\n",
      "to get us locked up \n",
      " what me and \n",
      " ya candle rhyme \n",
      " \n",
      " 'em pure i to i the the at and for\n",
      "\n",
      "\n",
      "Epoch 6/20\n",
      "Loss:    \t 5.658087730407715\n",
      "Accuracy:\t 13.222718238830566\n",
      "------Sampling----------\n",
      "seed: \tas real as it seems the american dream\n",
      "ain't nothing but another calculated schemes\n",
      "to get us locked up\n",
      "result:as real as it seems the american dream\n",
      "ain't nothing but another calculated schemes\n",
      "to get us locked up i \n",
      " man kick wanna we nigga and find \n",
      " us bum is this the nine \n",
      " your my get\n",
      "\n",
      "\n",
      "Epoch 7/20\n",
      "Loss:    \t 5.50604772567749\n",
      "Accuracy:\t 15.101234436035156\n",
      "------Sampling----------\n",
      "seed: \tas real as it seems the american dream\n",
      "ain't nothing but another calculated schemes\n",
      "to get us locked up\n",
      "result:as real as it seems the american dream\n",
      "ain't nothing but another calculated schemes\n",
      "to get us locked up to some shot \n",
      " i i motts the this flip world and \n",
      " i it call i goal get \n",
      "\n",
      "\n",
      "\n",
      "Epoch 8/20\n",
      "Loss:    \t 5.484649181365967\n",
      "Accuracy:\t 15.846795082092285\n",
      "------Sampling----------\n",
      "seed: \tas real as it seems the american dream\n",
      "ain't nothing but another calculated schemes\n",
      "to get us locked up\n",
      "result:as real as it seems the american dream\n",
      "ain't nothing but another calculated schemes\n",
      "to get us locked up to he poverty to out let's see now in walkin the homies fuckin \n",
      " the is me she and one\n",
      "\n",
      "\n",
      "Epoch 9/20\n",
      "Loss:    \t 5.306091785430908\n",
      "Accuracy:\t 16.095314025878906\n",
      "------Sampling----------\n",
      "seed: \tas real as it seems the american dream\n",
      "ain't nothing but another calculated schemes\n",
      "to get us locked up\n",
      "result:as real as it seems the american dream\n",
      "ain't nothing but another calculated schemes\n",
      "to get us locked up to that \n",
      " know you came it by get tons with \n",
      " we my need are with a \n",
      " to\n",
      "\n",
      "\n",
      "Epoch 10/20\n",
      "Loss:    \t 5.38442325592041\n",
      "Accuracy:\t 15.298588752746582\n",
      "------Sampling----------\n",
      "seed: \tas real as it seems the american dream\n",
      "ain't nothing but another calculated schemes\n",
      "to get us locked up\n",
      "result:as real as it seems the american dream\n",
      "ain't nothing but another calculated schemes\n",
      "to get us locked up to to be it \n",
      " i'm she pop now is come and of \n",
      " easy \n",
      " as flimflam wink a\n",
      "\n",
      "\n",
      "Epoch 11/20\n",
      "Loss:    \t 5.352932453155518\n",
      "Accuracy:\t 16.767780303955078\n",
      "------Sampling----------\n",
      "seed: \tas real as it seems the american dream\n",
      "ain't nothing but another calculated schemes\n",
      "to get us locked up\n",
      "result:as real as it seems the american dream\n",
      "ain't nothing but another calculated schemes\n",
      "to get us locked up \n",
      " for \n",
      " put in an hoop \n",
      " and baby the dream \n",
      " young dope a nigga \n",
      " nigga never\n",
      "\n",
      "\n",
      "Epoch 12/20\n",
      "Loss:    \t 5.008609294891357\n",
      "Accuracy:\t 18.55858612060547\n",
      "------Sampling----------\n",
      "seed: \tas real as it seems the american dream\n",
      "ain't nothing but another calculated schemes\n",
      "to get us locked up\n",
      "result:as real as it seems the american dream\n",
      "ain't nothing but another calculated schemes\n",
      "to get us locked up you fella bash to just role \n",
      " to to the ain't to of the raps \n",
      " ain't of nightmare into\n"
     ]
    }
   ],
   "source": [
    "import tools.processing as pre\n",
    "import tools.architectures as nn\n",
    "\n",
    "NUM_LAYERS = 2\n",
    "HIDDEN_LAYER_SIZE = 512\n",
    "VOCAB_SIZE = vocab.get_size()\n",
    "\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "rnn = SimpleMultiLayerRNN(name = \"multi-pac\")\n",
    "rnn.build(NUM_LAYERS, HIDDEN_LAYER_SIZE, VOCAB_SIZE, TIMESTEPS, l2_reg=0.0)\n",
    "\n",
    "sampler = lambda trainable, seed_text: tr.sample( seed_text, trainable, encoder, decoder, length=20)\n",
    "\n",
    "tr.train_model(rnn, data, labels, sampler, epochs=EPOCHS, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Sampling----------\n",
      "seed: \tkillin people left and right \n",
      " use a gun cool homie\n",
      "result:killin people left and right \n",
      " use a gun cool homie live rather and fuck out the that moocher steady piece \n",
      " that don't way a her i'm motherfuckin' \n",
      " i'm buck a one and come \n",
      " fuck fuck buck girl gets streets come and moms volcano can't sure killin on vicious fuck gon' \n",
      " all and think this \n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "decoder.temperature = 0.7\n",
    "\n",
    "sampler = lambda trainable, seed_text: tr.sample( seed_text, trainable, encoder, decoder, length=50)\n",
    "sampler(rnn, \"killin people left and right \\n use a gun cool homie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem\n",
    "\n",
    "How can we work out proper features from the text?\n",
    "\n",
    "Just because a line does not match 100% with the original one that doesn't mean that it is bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1093"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab._dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
