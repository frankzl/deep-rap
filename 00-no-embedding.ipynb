{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_name):\n",
    "    text = open(file_name, 'r').read()\n",
    "    return text.lower()\n",
    "\n",
    "\n",
    "class Alphabet:\n",
    "    def __init__(self, text):\n",
    "        from collections import Counter\n",
    "        self._count = Counter(list(text))\n",
    "        self._keys  = list(self._count.keys())\n",
    "        self._dict  = {}\n",
    "        for idx, key in enumerate(self._keys):\n",
    "            self._dict[key] = idx\n",
    "    \n",
    "    def get_count(self):\n",
    "        return self._count\n",
    "    \n",
    "    def get_size(self):\n",
    "        return len(self._keys)\n",
    "    \n",
    "    def letter_to_index(self, letter):\n",
    "        return self._dict.get( letter, 'err' )\n",
    "    \n",
    "    def index_to_letter(self, index):\n",
    "        return self._keys[index]\n",
    "    \n",
    "    def one_hot(self, text):\n",
    "        encoded = []\n",
    "        for letter in text:\n",
    "            one_hot = [0] * self.get_size()\n",
    "            one_hot[self.letter_to_index(letter)] = 1\n",
    "            encoded.append(one_hot)\n",
    "        return np.array(encoded)\n",
    "    \n",
    "    def to_text(self, one_hots):\n",
    "        indices = np.argmax( one_hots, axis=1 ).tolist()\n",
    "        return \"\".join([self.index_to_letter(idx) for idx in indices])\n",
    "    \n",
    "    def indices_to_text(self, indices):\n",
    "        print(\"shape\")\n",
    "        print(indices.shape)\n",
    "        _indices = indices.tolist()\n",
    "        print(_indices)\n",
    "        return \"\".join([self.index_to_letter(idx) for idx in _indices])\n",
    "        \n",
    "    \n",
    "text = read_data(\"data/cleaned-rap-lyrics/clean2_pac_.txt\")\n",
    "alphabet = Alphabet(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphabet.get_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded = np.array(alphabet.one_hot(text))\n",
    "encoded[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"as real as it seems the american dream\\nain't nothing but another calculated schemes\\nto get us locked\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphabet.to_text(encoded)[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_data(num_data, batch_size):\n",
    "    \"\"\" Yield batches with indices until epoch is over.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    num_data: int\n",
    "        The number of samples in the dataset.\n",
    "    batch_size: int\n",
    "        The batch size used using training.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    batch_ixs: np.array of ints with shape [batch_size,]\n",
    "        Yields arrays of indices of size of the batch size until the epoch is over.\n",
    "    \"\"\"\n",
    "    \n",
    "    # data_ixs = np.random.permutation(np.arange(num_data))\n",
    "    data_ixs = np.arange(num_data)\n",
    "    ix = 0\n",
    "    while ix + batch_size < num_data:\n",
    "        batch_ixs = data_ixs[ix:ix+batch_size]\n",
    "        ix += batch_size\n",
    "        yield batch_ixs\n",
    "\n",
    "def sample(predicted, temperature=0.5):\n",
    "    '''\n",
    "     helper function to sample an index from a probability array\n",
    "    '''\n",
    "    exp_predicted = np.exp(predicted/temperature)\n",
    "    predicted = exp_predicted / np.sum(exp_predicted)\n",
    "    probabilities = np.random.multinomial(1, predicted, 1)\n",
    "    return probabilities\n",
    "        \n",
    "class RNN:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        \n",
    "    def build(self, hidden_layer_size, vocab_size, time_steps, l2_reg=0.0):\n",
    "        self.time_steps = time_steps\n",
    "        self.vocab_size = vocab_size\n",
    "        \n",
    "        self.X = tf.placeholder(tf.float32, shape=[None, time_steps, vocab_size], name=\"data\")\n",
    "        self.Y = tf.placeholder(tf.int16, shape=[None, vocab_size], name=\"labels\")\n",
    "        \n",
    "        _X = tf.transpose(self.X, [1, 0, 2])\n",
    "        _X = tf.reshape(_X, [-1, vocab_size])\n",
    "        _X = tf.split(_X, time_steps, 0)\n",
    "        \n",
    "        with tf.variable_scope(self.name, reuse=tf.AUTO_REUSE):\n",
    "            self.rnn_cell   = tf.nn.rnn_cell.LSTMCell(hidden_layer_size)\n",
    "            \n",
    "            self.outputs, _ = tf.contrib.rnn.static_rnn(self.rnn_cell, _X, dtype=tf.float32)\n",
    "            \n",
    "            W_out = tf.Variable(tf.truncated_normal([hidden_layer_size, vocab_size], \n",
    "                                                 mean=0, stddev=.01))\n",
    "            b_out = tf.Variable(tf.truncated_normal([vocab_size],\n",
    "                                                mean=0, stddev=.01))\n",
    "            \n",
    "            self.weights.append(W_out)\n",
    "            self.biases.append(b_out)\n",
    "            \n",
    "            self.last_rnn_output = self.outputs[-1]\n",
    "            self.final_output    = self.last_rnn_output @ W_out + b_out\n",
    "            \n",
    "            self.softmax = tf.nn.softmax_cross_entropy_with_logits_v2(logits=self.final_output,\n",
    "                                                                labels=self.Y)\n",
    "            self.cross_entropy_loss = tf.reduce_mean(self.softmax)\n",
    "            \n",
    "            self.loss = self.cross_entropy_loss\n",
    "            \n",
    "            self.optimizer = tf.train.AdamOptimizer()\n",
    "            self.train_step= self.optimizer.minimize(self.loss)\n",
    "            \n",
    "            self.correct_prediction = tf.equal(tf.argmax(self.Y,1), tf.argmax(self.final_output, 1))\n",
    "            self.accuracy = tf.reduce_mean(tf.cast(self.correct_prediction, tf.float32))*100\n",
    "    \n",
    "    def train(self, train_data, train_labels, alphabet, epochs=20, batch_size=128):\n",
    "        train_losses = []\n",
    "        train_accs = []\n",
    "        \n",
    "        self.session = tf.Session()\n",
    "        session = self.session\n",
    "        \n",
    "        with session.as_default():\n",
    "            session.run(tf.global_variables_initializer())\n",
    "            tr_loss, tr_acc = session.run([self.loss, self.accuracy],\n",
    "                                          feed_dict={self.X: train_data,\n",
    "                                                     self.Y: train_labels})\n",
    "            train_losses.append(tr_loss)\n",
    "            train_accs.append(tr_acc)\n",
    "            \n",
    "            for epoch in range(epochs):\n",
    "                \n",
    "                if(epoch + 1) % 1 == 0:\n",
    "                    print(f\"\\n\\nEpoch {epoch + 1}/{epochs}\")\n",
    "                    print(f\"Loss:    \\t {tr_loss}\")\n",
    "                    print(f\"Accuracy:\\t {tr_acc}\")\n",
    "                \n",
    "                for batch_ixs in batch_data(len(train_data), batch_size):\n",
    "                    _ = session.run(self.train_step,\n",
    "                                   feed_dict={\n",
    "                                       self.X: train_data[batch_ixs],\n",
    "                                       self.Y: train_labels[batch_ixs],\n",
    "                                   })\n",
    "                tr_loss, tr_acc = session.run([self.loss, self.accuracy],\n",
    "                                               feed_dict={self.X: train_data,\n",
    "                                                          self.Y: train_labels\n",
    "                                                         })\n",
    "                train_losses.append(tr_loss)\n",
    "                train_accs.append(tr_acc)\n",
    "                \n",
    "                #get on of training set as seed\n",
    "                seed = train_data[:1:]\n",
    "        \n",
    "                #to print the seed 40 characters\n",
    "                seed_chars = ''\n",
    "                for each in seed[0]:\n",
    "                    seed_chars += alphabet._keys[np.where(each == max(each))[0][0]]\n",
    "                print (\"Seed:\" + seed_chars)\n",
    "        \n",
    "                #predict next 500 characters\n",
    "                for i in range(500):\n",
    "                    if i > 0:\n",
    "                        remove_fist_char = seed[:,1:,:]\n",
    "                        seed = np.append(remove_fist_char, np.reshape(probabilities, [1, 1, self.vocab_size]), axis=1)\n",
    "                        \n",
    "                    predicted = session.run([self.final_output], feed_dict = {self.X:seed})\n",
    "                    predicted = np.asarray(predicted[0]).astype('float64')[0]\n",
    "                    probabilities = sample(predicted)\n",
    "                    predicted_chars = alphabet._keys[np.argmax(probabilities)]\n",
    "                    seed_chars += predicted_chars\n",
    "                print ('Result:'+ seed_chars)\n",
    "        \n",
    "        self.hist = {\n",
    "            'train_losses': np.array(train_losses),\n",
    "            'train_accuracy': np.array(train_accs)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = read_data('data/cleaned-rap-lyrics/clean2_pac_.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 1\n",
    "\n",
    "HIDDEN = 256\n",
    "VOCAB_SIZE = 31\n",
    "TIME_STEPS = 50\n",
    "EPOCHS = 50\n",
    "\n",
    "def read_data(file_name):\n",
    "    '''\n",
    "     open and read text file\n",
    "    '''\n",
    "    text = open(file_name, 'r').read()\n",
    "    return text.lower()\n",
    "\n",
    "def making_one_hot(text, alphabet):\n",
    "    '''\n",
    "    '''\n",
    "    unique_chars = alphabet._keys\n",
    "    len_unique_chars = len(unique_chars)\n",
    "\n",
    "    input_chars = []\n",
    "    output_char = []\n",
    "    for i in range(0, len(text) - TIME_STEPS, step):\n",
    "        input_chars.append(text[i:i+TIME_STEPS])\n",
    "        output_char.append(text[i+TIME_STEPS])\n",
    "    train_data = np.zeros((len(input_chars), TIME_STEPS, len_unique_chars))\n",
    "    target_data = np.zeros((len(input_chars), len_unique_chars))\n",
    "    for i , each in enumerate(input_chars):\n",
    "        for j, char in enumerate(each):\n",
    "            train_data[i, j, unique_chars.index(char)] = 1\n",
    "        target_data[i, unique_chars.index(output_char[i])] = 1\n",
    "    return train_data, target_data, unique_chars, len_unique_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_data, tr_labels, unique_chars, len_unique = making_one_hot(text, alphabet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-bbd6022f93ee>:52: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').\n",
      "\n",
      "\n",
      "Epoch 1/50\n",
      "Loss:    \t 3.4325194358825684\n",
      "Accuracy:\t 4.09566068649292\n",
      "Seed:as real as it seems the american dream\n",
      "ain't nothi\n",
      "Result:as real as it seems the american dream\n",
      "ain't nothiu    e s    a   ra e  toenet ity s n n a  iywl    y toi e    tto  t  ae       u  t   neo o te  reoor e aru yu  h   i e    t  d    h eeo  o o te t nb   t h  uh      irm o        ul ytt u   t     hy\n",
      "  m i u  e \n",
      "  rsee a nt  r  pa  e  yie u ee eyoe  ed y  l h e o t  y e  i    a        hta toa  h   ne   eei  h e ei ioa  y heo  oa  uon  o     oaa yom   rt     ee  e t  di    a  li oe sehe t o e     i  te     e h ents   o  a   eyhn   s i ooe a  e   sotn  etnio aney e ap aad r ee rohi  l e t enir   t  o\n",
      "\n",
      "\n",
      "Epoch 2/50\n",
      "Loss:    \t 2.9359688758850098\n",
      "Accuracy:\t 17.848106384277344\n",
      "Seed:as real as it seems the american dream\n",
      "ain't nothi\n",
      "Result:as real as it seems the american dream\n",
      "ain't nothiar a am  ot tee  oo tort lo  e s tot he oiay tot tor  oo n ase e faa tr io  ia mt ae  e y lat an  yath dotr ni r sh he ye t iay ra s san co n an r ao nut toou tt e uo st so  wou uy  om \n",
      "oe yo y uy te the r to e eo n aed tur  oeu ee to e ln  ot d no ch ke u a \n",
      "ui  ay wow io  oe d ne mo  ie e  he  od d se e tee ime e to  un rot te wo \n",
      "ro  har d e fh aoy  ho  aro re oo le  ha  we t te  oo tay re mo t lou dot to nh  he n tou  t oy ie u to  tat se  oo  se ton  he rr t to  oor  ey rtr te d tot  he uoo\n",
      "\n",
      "\n",
      "Epoch 3/50\n",
      "Loss:    \t 2.731052875518799\n",
      "Accuracy:\t 21.83397674560547\n",
      "Seed:as real as it seems the american dream\n",
      "ain't nothi\n",
      "Result:as real as it seems the american dream\n",
      "ain't nothit the bawi yer yor in mor ye to the lon rye le shit toye the re tou toe wou tho yor fe the the dho t aocy in ne tou an he tore tou tot tot eot in gin lore io  hou ie the iod ye toe you se ao d ao aa bhhe  waut aas tin tou tou wov whe lo tot ao whe yoc to s yoc mo tou tit il  you sof lou yhe thar nh it tose\n",
      "to tat tou is ne th at ye the do ho ny in se son toe bow too te that yot  in so the bot y pe son yhe y yhe sou soy mou s aoe the the shet sute io mirh an redt aan tea bol so nh the the thee io\n",
      "\n",
      "\n",
      "Epoch 4/50\n",
      "Loss:    \t 2.529972553253174\n",
      "Accuracy:\t 27.294858932495117\n",
      "Seed:as real as it seems the american dream\n",
      "ain't nothi\n",
      "Result:as real as it seems the american dream\n",
      "ain't nothi in soy wou mon toa dhe tou the cou  out wato le weus sop the wan the the the an at an se eo seos eoo in thy yhu le ro the me in the ine an in the pould faute i weo the mas it wou dere tiun bean sof i care wo ree the the so u wat the the sare wou ine onr oe dou s it houl iny in in wha cama tou ke eir dot as wot the w aume ir onas eoe ge te rou i toe wous ont yhus in wand wtuut waun seeo thin hor ther whe to aot you rros bat ay tou me she keo ap nor wot so weyt be tous waat tou the wou we the me \n",
      "\n",
      "\n",
      "Epoch 5/50\n",
      "Loss:    \t 2.4151599407196045\n",
      "Accuracy:\t 29.352235794067383\n",
      "Seed:as real as it seems the american dream\n",
      "ain't nothi\n",
      "Result:as real as it seems the american dream\n",
      "ain't nothi lout chepe tou yor whan an the sou eee it an tou home tou san' sou the leot an me boun bope in wofe eas the the tha kt pean ther an thet loc aut a it iy you gat foud ind ther it thou be bee caake thon doo ther tou sou the whou ther y an fou the an the the why are lire in me veos hou heus you the the dor at suy you sou thon m the ine sos ru me win too the me tou the sole ao me toad the tho dand heas the cyau hee an to the doul iny io det fou she hine in the in' sans mu the mou band in that is yo\n",
      "\n",
      "\n",
      "Epoch 6/50\n",
      "Loss:    \t 2.3373842239379883\n",
      "Accuracy:\t 30.45491600036621\n",
      "Seed:as real as it seems the american dream\n",
      "ain't nothi\n",
      "Result:as real as it seems the american dream\n",
      "ain't nothin' nou coy is in the be boul eon sout sou the foove it seut fou the herind and i meplans the the shou the ge wher the heat out an in tho me beat ir in shea you woy wart here woun to the deat here bun whan to heo it het it whet buco me in wanl\n",
      "to the seas in wher you you cous ir seand the gous io ly sour the elis sout io the sith roule goure ion you ther leret in the wond me me it wor sive weon the be tou the sine an woan sout soe poe dore tor wire the the ere as houc to lethe met woo they me hei\n",
      "\n",
      "\n",
      "Epoch 7/50\n",
      "Loss:    \t 2.272261381149292\n",
      "Accuracy:\t 31.977659225463867\n",
      "Seed:as real as it seems the american dream\n",
      "ain't nothi\n",
      "Result:as real as it seems the american dream\n",
      "ain't nothin' i chee the dan' in whe liy in ther soule i the yous in the the ther in meas and bean bear the wand the aoon wact in tha thet coud bet be my wamt i've ther ind dathe me fous you the ind wand you slat the tou in's you ther hea ing me heal\n",
      "she sare the lith cind the soon the beale is i stoe toun ind the uthe hean and ane\n",
      "you seont bur se dos ind hour and ir you stour oud in mome sou keat i the bet ay me feap the ato inm that it fhe keacher at in met it lin the sto she the leas the ot so dere\n",
      "gon\n",
      "\n",
      "\n",
      "Epoch 8/50\n",
      "Loss:    \t 2.219477415084839\n",
      "Accuracy:\t 33.68657302856445\n",
      "Seed:as real as it seems the american dream\n",
      "ain't nothi\n",
      "Result:as real as it seems the american dream\n",
      "ain't nothin the canche geat\n",
      "you stone in whan i the rore me bere i at in wher i wat the beat wame i mut the the the the the mind ar the the stoun sous nou the me sale on way oucs and i woon tou sust i me ior at ther ind ne fous seat sor the heat in to is a meat tou bit the s ass souk the the beat you med i fout in't a ire hea cay head the mith the me bealin to and heat ird and in werer the methen wire i me it i stor erey four the cand mo thind you the top you fout i to in i me i dout so at an wo last i we\n",
      "\n",
      "\n",
      "Epoch 9/50\n",
      "Loss:    \t 2.1737332344055176\n",
      "Accuracy:\t 35.1759033203125\n",
      "Seed:as real as it seems the american dream\n",
      "ain't nothi\n",
      "Result:as real as it seems the american dream\n",
      "ain't nothith nor i the win' you whos beave and an whe lather the to i mo gond you stot bus the an the the sele but streo it it wire wore min' ind you sed you the coule i you me to ley the you then the sind pool i' my the thy an you seat i you geat cous or me way you heat you lin the heca haw wank the thas hot the lin me in we the to pone hear in the the lin thee mist i caud the me way in ther caus the cherle a the dane it ar me the the to syou i my pooky a lith tho bean wond and the wand and the wond beas\n",
      "\n",
      "\n",
      "Epoch 10/50\n",
      "Loss:    \t 2.131807565689087\n",
      "Accuracy:\t 36.421783447265625\n",
      "Seed:as real as it seems the american dream\n",
      "ain't nothi\n",
      "Result:as real as it seems the american dream\n",
      "ain't nothin's you the kit' i wall heve wey done tret in whe sint i hat i lisl i me wey i caule head you the doun whe bea shee thet in lead sine i cand i me pane\n",
      "now in ware the beat do leand you mus the mis to en the my hor in to me wind got lat you stout we than the kere and fere bick of in lind ho ston in llat you bean weat the i to ger the an and no dest it you the the tee thin' you lion and on whe hear and hear the reed to the thy are coull the ather the ceosl the tout to leve the rous i'w the pank yo\n",
      "\n",
      "\n",
      "Epoch 11/50\n",
      "Loss:    \t 2.096675157546997\n",
      "Accuracy:\t 37.4099006652832\n",
      "Seed:as real as it seems the american dream\n",
      "ain't nothi\n",
      "Result:as real as it seems the american dream\n",
      "ain't nothin and you dyou and the deon thor i care you ker the wens the whe snace you ston the coure i me stare thit my ald ler wyous an the me and nat i llis a cone bean o me for bed the keon min the store four we wis the min' ofe the hean that i'm the it th ther an the pine gove fat the me beam be bat the the dous ou the the the jusl you wand beat you me beat eow the keor weat low to her the lit me make e the the thet you coull the to love in the din't to stoy an ous the caree wand a me sadin whet you me\n",
      "\n",
      "\n",
      "Epoch 12/50\n",
      "Loss:    \t 2.0702943801879883\n",
      "Accuracy:\t 37.89679718017578\n",
      "Seed:as real as it seems the american dream\n",
      "ain't nothi\n",
      "Result:as real as it seems the american dream\n",
      "ain't nothin' to sto the the dan sicke me at whe the is an the wast he lite in i f he lond you ho land i cars and i keat git ston't in shey live i the din' and the the ston to forl whe let ware so in the leed now the my io the ceand ne wer me store the keat i fo ly beald i my i keal the coull you wand the eres i me me the cand i my my hour ous the win the lall thy on the my hat so rore on the whe wand\n",
      "you llee the f ond bist the the cous i my now th the sted fer the win' i wes you that the win' on the what\n",
      "\n",
      "\n",
      "Epoch 13/50\n",
      "Loss:    \t 2.0516247749328613\n",
      "Accuracy:\t 38.39324188232422\n",
      "Seed:as real as it seems the american dream\n",
      "ain't nothi\n",
      "Result:as real as it seems the american dream\n",
      "ain't nothin' the nover sead\n",
      "i wis  you les i the lin' eren a dis the dand the lose wis now i'm rein' het you lond they i me line my don i my wiy mith whan you din wor me to des lat you soy the din' wark the stoy i my le the whed your in the ind of wes wint i me hith you dand i my beat i me in my het i dey bus my my head i whe the cause you keep in the phead you lead i cand the steed the whet i my her the hand un so me i leve the wack you the ring the le wean weand eroy the dor cause my lick now the heam s\n",
      "\n",
      "\n",
      "Epoch 14/50\n",
      "Loss:    \t 2.0294699668884277\n",
      "Accuracy:\t 38.75125503540039\n",
      "Seed:as real as it seems the american dream\n",
      "ain't nothi\n",
      "Result:as real as it seems the american dream\n",
      "ain't nothin sist you to stres the klove oull now you lose\n",
      "to end you rof i get but but be let the leve sweat be the suy i ster beand and your ded bord he doo her i'm the don in you stee i't wan' wind strecate do head eo het in the the to get i my i whe stor the the het i hem dous\n",
      "on and pith i dand now i to ster the a me heald the dyou the but in the the bus store drop ne the wat i don the rond i me the beat i whe st the got you the the houck in the whet like you reed he bee stist i lat to how i wat i kan\n",
      "\n",
      "\n",
      "Epoch 15/50\n",
      "Loss:    \t 2.0068933963775635\n",
      "Accuracy:\t 39.14745330810547\n",
      "Seed:as real as it seems the american dream\n",
      "ain't nothi\n",
      "Result:as real as it seems the american dream\n",
      "ain't nothin you could you dut you roon you anver the cande to het it to my heat ous ou bay i me the the lith you stin' to rean met war the herise the heare a could i know st the wead you the stor i weat her fee the with the my hear ad the but serad me\n",
      "the beat to my i'm and beve\n",
      "in whe and stor how it you lis you roy i'm the the in' and beat to soud on the kin' houre a the store on bus i wear you deon to the frores dere an the the mick in yo reettin' a could the her don' the me pishe wen i steat i for str\n",
      "\n",
      "\n",
      "Epoch 16/50\n",
      "Loss:    \t 1.9786969423294067\n",
      "Accuracy:\t 39.94940185546875\n",
      "Seed:as real as it seems the american dream\n",
      "ain't nothi\n",
      "Result:as real as it seems the american dream\n",
      "ain't nothin the lous i caus to done you penty my i hat i wand whe know tha kun't i wat de wond i weon whan i me ate a the lin so beati now steen a got i's on the that heve i wis story be the the stor i the kin you head i me whend wer gever that i me whe wiy sant wers i with the keat fo stor serin'\n",
      "you cast cous in i me as my bere an wha llang you leath i win' to me i cause i with for the and dean i ges the whe stret whed to hot i me boy the hould you cand the line for the ping you rean wen the the wyoy ca\n",
      "\n",
      "\n",
      "Epoch 17/50\n",
      "Loss:    \t 1.9551852941513062\n",
      "Accuracy:\t 40.78476333618164\n",
      "Seed:as real as it seems the american dream\n",
      "ain't nothi\n",
      "Result:as real as it seems the american dream\n",
      "ain't nothin' gow you hear th se i fore i my her stupbed leve i lay the hocrlin for a fore i wand the me\n",
      "i my hinger the weand wendin' you ghe wand i fand the bean and hik go d i kloust i got my pist i wan the bopl that hearl din's a wat i we the asd the the crute on you the when the hous fer be i cause a dond i me the her be beat in the lond now thet becker start you now you whe stiell beat cause you ham\n",
      "the but the hon i statted the kin' the hand i my hear he fere i how a the kin' ous and you hear be bea\n",
      "\n",
      "\n",
      "Epoch 18/50\n",
      "Loss:    \t 1.9323160648345947\n",
      "Accuracy:\t 41.596256256103516\n",
      "Seed:as real as it seems the american dream\n",
      "ain't nothi\n",
      "Result:as real as it seems the american dream\n",
      "ain't nothin' a and i dein in the kink the the fore wis i fand so read i me the wers i dom the wes forsted i knover cand now ro kin' the the keow no like my part i how the loon you bet my hond worl sthen i my heal you now the leake i my pust or the me and my hith to how the loon a me beat not it'll now the pind he lon' to steat you and my steet the kin' love and do her store to let crock dame you the beat a know the hour the like start hears nave and is the wind the thit to you the tome to i wat me sore i \n",
      "\n",
      "\n",
      "Epoch 19/50\n",
      "Loss:    \t 1.9106539487838745\n",
      "Accuracy:\t 42.23113250732422\n",
      "Seed:as real as it seems the american dream\n",
      "ain't nothi\n",
      "Result:as real as it seems the american dream\n",
      "ain't nothin hear your i the stond i my when my ut that stop the my heare the kyou ta ke me is so can't i'm the the see the lock you when the fere the kin's got be that thes fond for get the werle whe hes i wand to can the the sters ro know i'm than the lang the wand the keet me hould i know but stell you dann so ryon a fore a to stor the couss eack you and you cause i lock can i to rove in hear\n",
      "the now the hour be the the the beat i can the a ho doon the me to my hearty the hou and beat in i know my moch \n",
      "\n",
      "\n",
      "Epoch 20/50\n",
      "Loss:    \t 1.8890156745910645\n",
      "Accuracy:\t 42.928062438964844\n",
      "Seed:as real as it seems the american dream\n",
      "ain't nothi\n",
      "Result:as real as it seems the american dream\n",
      "ain't nothin wan you wand the dion thit stous thin the hourt you wen streed the store the lothe weed for dever what on my you the ghee to like on the my heart i could to ster ti che bond becand that so you the wathe you how the heare is mo bay you reac for be the crockn't i tom the know you hall the to stemt i me my end the hould hear i lake my the the foon you row you hear an the routh i caule my heart\n",
      "you wes strind to het in the ind\n",
      "the the hear you did sweek to the stople i don dour you min' you wer th\n",
      "\n",
      "\n",
      "Epoch 21/50\n",
      "Loss:    \t 1.8689302206039429\n",
      "Accuracy:\t 43.44837188720703\n",
      "Seed:as real as it seems the american dream\n",
      "ain't nothi\n",
      "Result:as real as it seems the american dream\n",
      "ain't nothin you get hor i hat when of you the lith i'm the know i lot you roon lold could werl ge the tink of my best the lick yo recker start to heal the startin'\n",
      "you and hear the the bust i my for the tis a doon you swer the kin' the the lich a dould on the kinf a stee lane the cause i hey be beat you the lyaus that you like i pond sere the loon a dis the keys to wet my wit the houre you wand to deon go dith rove i me and streck to don't i me lock i can't you'r they you he drope i sterl do pere i frel t\n",
      "\n",
      "\n",
      "Epoch 22/50\n",
      "Loss:    \t 1.848760724067688\n",
      "Accuracy:\t 43.87799072265625\n",
      "Seed:as real as it seems the american dream\n",
      "ain't nothi\n",
      "Result:as real as it seems the american dream\n",
      "ain't nothin you the meart could beat you me stick the lath nove my hetaty my procked how i wat you wes for the when you loon i ke wly you bet mut i' ly pith i mncare leck the like me the ats din the lof you the lit i mave like wish the don't coul you deon a start go line i canin i hay you roy the myous the pone and my myse when the talle af streply i cond the ropped to you all me beat you head to and the fore i why and you roy you get out you herl the weath i cause you don' beat i wan you sarn i me con th\n",
      "\n",
      "\n",
      "Epoch 23/50\n",
      "Loss:    \t 1.8289214372634888\n",
      "Accuracy:\t 44.26941680908203\n",
      "Seed:as real as it seems the american dream\n",
      "ain't nothi\n",
      "Result:as real as it seems the american dream\n",
      "ain't nothin the couse the houre i got i wat you wenn the houst poof on the hith the hous of my for sa the ast i me steen you ray the lick i know be the hor the the like you get dith the wand i me my peath you canity stupken you and you he and you steat ho din' beat to dens lake s cause i'm that steake doye wit on my chend for the sous you rey up you sweet a cane i cruld het here you geve mese wear the ane the lick the her the hex the hond the could you cour beat to the wink it tile you want i can the phet\n",
      "\n",
      "\n",
      "Epoch 24/50\n",
      "Loss:    \t 1.8072423934936523\n",
      "Accuracy:\t 44.885196685791016\n",
      "Seed:as real as it seems the american dream\n",
      "ain't nothi\n",
      "Result:as real as it seems the american dream\n",
      "ain't nothin the kin the mich you reed the like i fare the kin't way he roy hous the the like and of the whet my heart the depp i for the hep the now you don't me hore the fust i wat i now i wee it to know the lloty thy could a sweat i got tis the the but my fumbed to the ate you wen i ho at it with the din the cause the houre of here the they hyre the wis so strype a to the for my reawe dan' the furlte the hour he my siget it the kis that my michous heer a dack nat the know you hove lith to s and streed t\n",
      "\n",
      "\n",
      "Epoch 25/50\n",
      "Loss:    \t 1.7856887578964233\n",
      "Accuracy:\t 45.62031555175781\n",
      "Seed:as real as it seems the american dream\n",
      "ain't nothi\n",
      "Result:as real as it seems the american dream\n",
      "ain't nothin cause i get me the hyou when the stare be boand you reant me like seruse you hear my beat you don't to kyo coullin' beat i can the whon was i keac that se wart when you hear my mecane i wis the dow i streath i love my heon\n",
      "my to know the lone i was i dope that so hand i cause in i heart start i gat an bean the coure git to wend streck and my could i cause i stop the lich so you the the mere to the myse my are veald whet lot you lith you scoor you reant stout un the lith i could i fo drop the l\n",
      "\n",
      "\n",
      "Epoch 26/50\n",
      "Loss:    \t 1.7651091814041138\n",
      "Accuracy:\t 46.221778869628906\n",
      "Seed:as real as it seems the american dream\n",
      "ain't nothi\n",
      "Result:as real as it seems the american dream\n",
      "ain't nothin the fure let the lith the chome you can the onith a the din you stien tous the beat to see to my now i'm stere a was ho fore you dad a way the stust beat on the hour to a the hour the pock on the the free sa kin' i more on the to heart to stee the hour hy heart i wes hard we the know i'm the canse i could the lyou how i worl the hop the me beat me but i was the lied to me i my wism i want i want wer and i reapt styep the loy it a doon and i to the meck that i wond a mad i sthe dizzy with the h\n",
      "\n",
      "\n",
      "Epoch 27/50\n",
      "Loss:    \t 1.7449405193328857\n",
      "Accuracy:\t 46.79936981201172\n",
      "Seed:as real as it seems the american dream\n",
      "ain't nothi\n",
      "Result:as real as it seems the american dream\n",
      "ain't nothing i way in the lith we the home\n",
      "wat ho dad of the casse it my worne defe to know the don't care hear to know i my her hear my lock i cauld you're stoat\n",
      "i love of beat i wand to dene ho dand up thy to the wis i start you wist to the tist what now you heart you we the could the know it my hertant\n",
      "no least love i mad to my low you the chope on the furke sake to it to heart i got i know stoover me my you steet to me hon i get on the steak and the could worn the hiss to the hat ho read a dack could \n",
      "\n",
      "\n",
      "Epoch 28/50\n",
      "Loss:    \t 1.7297412157058716\n",
      "Accuracy:\t 47.090553283691406\n",
      "Seed:as real as it seems the american dream\n",
      "ain't nothi\n",
      "Result:as real as it seems the american dream\n",
      "ain't nothin and i knever se fare i cull now the weart can the toon the kio hore you the fore her eand i be the my his dool the cause i know the for i wank the and you the lion i get lake me a to kin the fore my hearte wanne sear a day the dant with i can beat stop the other be to fer the could nover cause i stell the can hor streant the bust i fry the leath\n",
      "i wear you wey car stret it wank you wond you and you when my my heart my hack i was a doon the cante mecher i wan s he rongy of my a was to me hear i\n",
      "\n",
      "\n",
      "Epoch 29/50\n",
      "Loss:    \t 1.7078332901000977\n",
      "Accuracy:\t 47.692012786865234\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-2eac84d7df68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbasicRNN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"basic\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mbasicRNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHIDDEN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVOCAB_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTIME_STEPS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mbasicRNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malphabet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-bbd6022f93ee>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_data, train_labels, alphabet, epochs, batch_size)\u001b[0m\n\u001b[1;32m    102\u001b[0m                                    feed_dict={\n\u001b[1;32m    103\u001b[0m                                        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_ixs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                                        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_ixs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                                    })\n\u001b[1;32m    106\u001b[0m                 tr_loss, tr_acc = session.run([self.loss, self.accuracy],\n",
      "\u001b[0;32m~/.envs/env36-ml/.venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.envs/env36-ml/.venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.envs/env36-ml/.venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.envs/env36-ml/.venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.envs/env36-ml/.venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.envs/env36-ml/.venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "basicRNN = RNN(name = \"basic\")\n",
    "basicRNN.build(HIDDEN, VOCAB_SIZE, TIME_STEPS)\n",
    "basicRNN.train(tr_data, tr_labels, alphabet, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
