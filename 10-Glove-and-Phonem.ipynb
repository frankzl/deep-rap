{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorboard.plugins import projector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tools.processing as pre\n",
    "import tools.embedding as emb\n",
    "import tools.architectures as nn\n",
    "import tools.training as tr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create embedding for words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.03209195  0.06766261  0.04151145 ... -0.046448   -0.03842104\n",
      "  -0.04822   ]\n",
      " [ 0.00029647  0.01313631 -0.0196403  ... -0.0001816   0.00719928\n",
      "   0.00517092]\n",
      " [ 0.00825335  0.00466938 -0.03945393 ... -0.0567189  -0.02748226\n",
      "   0.0531178 ]\n",
      " ...\n",
      " [-0.0196528   0.05993839 -0.09010126 ...  0.00900052  0.04102224\n",
      "  -0.00091614]\n",
      " [-0.00165838 -0.00060007 -0.0861928  ...  0.03562126 -0.0017157\n",
      "  -0.04269713]\n",
      " [ 0.03778261 -0.01219655 -0.05140489 ...  0.00514077 -0.03030926\n",
      "  -0.04753494]]\n"
     ]
    }
   ],
   "source": [
    "text = pre.get_text(\"data/cleaned-rap-lyrics/final_2_pac_rakim_kid_cudi.txt\")[:10000]\n",
    "\n",
    "vocab = pre.Vocabulary(text)\n",
    "word2index = vocab.word2index\n",
    "index2word = vocab.index2word\n",
    "VOCAB_SIZE = len(index2word)\n",
    "\n",
    "# create embedding for words\n",
    "word_embedding_matrix = emb.get_embedding_matrix(word2index, VOCAB_SIZE)\n",
    "print(word_embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "595\n"
     ]
    }
   ],
   "source": [
    "print(VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create embedding for phonems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phonems = pre.get_text(\"data/phonem-rap-lyrics/phonem_all.txt\")\n",
    "\n",
    "vocab_phonem = pre.Vocabulary(phonems)\n",
    "phonem2index = vocab_phonem.word2index\n",
    "index2phonem = vocab_phonem.index2word\n",
    "VOCAB_SIZE_PHONEM = len(index2phonem)\n",
    "\n",
    "# create embedding for phonems\n",
    "phonem_embedding_matrix = emb.get_phonem_embedding_matrix(phonem2index, VOCAB_SIZE_PHONEM)\n",
    "print(phonem_embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(VOCAB_SIZE_PHONEM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation: Split sentences of text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['yeah', 'you', 'know', 'what', 'this', 'is', 'nyc', ';', 'the', 'triumphant', 'return', 'rakim', 'allah', ';', 'rakim', ';'], 'remember'), (['you', 'know', 'what', 'this', 'is', 'nyc', ';', 'the', 'triumphant', 'return', 'rakim', 'allah', ';', 'rakim', ';', 'remember'], 'being'), (['know', 'what', 'this', 'is', 'nyc', ';', 'the', 'triumphant', 'return', 'rakim', 'allah', ';', 'rakim', ';', 'remember', 'being'], 'introduced'), (['what', 'this', 'is', 'nyc', ';', 'the', 'triumphant', 'return', 'rakim', 'allah', ';', 'rakim', ';', 'remember', 'being', 'introduced'], 'to'), (['this', 'is', 'nyc', ';', 'the', 'triumphant', 'return', 'rakim', 'allah', ';', 'rakim', ';', 'remember', 'being', 'introduced', 'to'], 'rapping')]\n"
     ]
    }
   ],
   "source": [
    "word_tokens = text.split()\n",
    "\n",
    "TIMESTEPS = 16\n",
    "\n",
    "str_data, str_labels = pre.create_data_label_pairs(word_tokens, TIMESTEPS)\n",
    "\n",
    "print( list( zip(str_data, str_labels) )[:5] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = tr.OneHotWordEncoder(\"1-Hot-Word-Encoding\", word2index)\n",
    "decoder = tr.OneHotWordDecoder(\"1-Hot-Word-Decoding\", index2word, temperature=0.8)\n",
    "\n",
    "data = encoder.encode(str_data)\n",
    "labels = encoder.encode_labels(str_labels)\n",
    "\n",
    "del str_labels\n",
    "del str_data\n",
    "del word_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2084, 16, 595)\n",
      "(2084, 595)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Get seqlens of rap lyrics and phonem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRE_TRAINED = True\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "embedding_dimension = 64\n",
    "embedding_dimension_phonem = 3\n",
    "\n",
    "hidden_layer_size = 32\n",
    "hidden_layer_size_phonem = 16\n",
    "\n",
    "num_LSTM_layers = 4\n",
    "num_LSTM_layers_phonem = 4\n",
    "\n",
    "#times_steps = 16        # TODO max seqlen of rap text sentence\n",
    "times_steps_phonem = 16 # TODO max seqlen of phonem sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create input placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n_inputs = tf.placeholder(tf.int32, shape=[BATCH_SIZE, times_steps])\\nembedding_placeholder = tf.placeholder(tf.float32, [VOCAB_SIZE, emb.GLOVE_SIZE])\\n_labels = tf.placeholder(tf.float32, shape=[BATCH_SIZE, VOCAB_SIZE])\\n_seqlens = tf.placeholder(tf.int32, shape=[BATCH_SIZE])\\n\\n_inputs_phonem = tf.placeholder(tf.int32, shape=[BATCH_SIZE, times_steps_phonem])\\nembedding_placeholder_phonem = tf.placeholder(tf.float32, [VOCAB_SIZE_PHONEM, emb.PHONEM_SIZE])\\n_labels_phonem = tf.placeholder(tf.float32, shape=[BATCH_SIZE, VOCAB_SIZE_PHONEM]) # TODO do we need this? label should be only one?\\n_seqlens_phonem = tf.placeholder(tf.int32, shape=[BATCH_SIZE])\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create input placeholders\n",
    "'''\n",
    "_inputs = tf.placeholder(tf.int32, shape=[BATCH_SIZE, times_steps])\n",
    "embedding_placeholder = tf.placeholder(tf.float32, [VOCAB_SIZE, emb.GLOVE_SIZE])\n",
    "_labels = tf.placeholder(tf.float32, shape=[BATCH_SIZE, VOCAB_SIZE])\n",
    "_seqlens = tf.placeholder(tf.int32, shape=[BATCH_SIZE])\n",
    "\n",
    "_inputs_phonem = tf.placeholder(tf.int32, shape=[BATCH_SIZE, times_steps_phonem])\n",
    "embedding_placeholder_phonem = tf.placeholder(tf.float32, [VOCAB_SIZE_PHONEM, emb.PHONEM_SIZE])\n",
    "_labels_phonem = tf.placeholder(tf.float32, shape=[BATCH_SIZE, VOCAB_SIZE_PHONEM]) # TODO do we need this? label should be only one?\n",
    "_seqlens_phonem = tf.placeholder(tf.int32, shape=[BATCH_SIZE])\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"embeddings\"):\n",
    "    if PRE_TRAINED:\n",
    "        embeddings = tf.Variable(tf.constant(0.0, shape=[VOCAB_SIZE, emb.GLOVE_SIZE]), trainable=True)\n",
    "        # If using pretrained embeddings, assign them to the embeddings variable\n",
    "        embedding_init = embeddings.assign(embedding_placeholder)\n",
    "        embed = tf.nn.embedding_lookup(embeddings, _inputs)\n",
    "    else:\n",
    "        embeddings = tf.Variable(tf.random_uniform([VOCAB_SIZE, embedding_dimension],\n",
    "                                                   -1.0, 1.0))\n",
    "        embed = tf.nn.embedding_lookup(embeddings, _inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phonem embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"embeddings_phonem\"):\n",
    "    if PRE_TRAINED:\n",
    "        embeddings_phonem = tf.Variable(tf.constant(0.0, shape=[VOCAB_SIZE_PHONEM, emb.PHONEM_SIZE]), trainable=True)\n",
    "        # If using pretrained embeddings, assign them to the embeddings variable\n",
    "        embedding_init_phonem = embeddings_phonem.assign(embedding_placeholder_phonem)\n",
    "        embed_phonem = tf.nn.embedding_lookup(embeddings_phonem, _inputs_phonem)\n",
    "    else:\n",
    "        embeddings_phonem = tf.Variable(tf.random_uniform([VOCAB_SIZE_PHONEM, embedding_dimension_phonem],\n",
    "                                                   -1.0, 1.0))\n",
    "        embed_phonem = tf.nn.embedding_lookup(embeddings_phonem, _inputs_phonem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/rene/workspace/Tensorflow/.pyenv/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/rene/workspace/Tensorflow/Seminar NLP/Project/deep-rap/tools/architectures.py:246: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /Users/rene/workspace/Tensorflow/Seminar NLP/Project/deep-rap/tools/architectures.py:249: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From /Users/rene/workspace/Tensorflow/Seminar NLP/Project/deep-rap/tools/architectures.py:368: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /Users/rene/workspace/Tensorflow/.pyenv/lib/python3.7/site-packages/tensorflow/python/ops/array_grad.py:425: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "rnn_words = nn.MultiLayerRNN_v2(name=\"lstm-words\")\n",
    "rnn_words.build(num_LSTM_layers, hidden_layer_size, VOCAB_SIZE, TIMESTEPS, l2_reg=0.0, embedding_dim=emb.GLOVE_SIZE)\n",
    "\n",
    "sampler = lambda trainable, seed_text: tr.sample(seed_text, trainable, encoder, decoder, length=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model from scratch! \n",
      " Saving into: '../logs/10-test-glove'\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (2084, 16, 595) for Tensor 'data:0', which has shape '(?, 16)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-f41b09c5a902>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"logs/10-test-glove\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \"\"\"\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"lstm\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Define a function that gives the output in the right shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/Tensorflow/Seminar NLP/Project/deep-rap/tools/training.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(trainable, train_data, train_labels, sampler, epochs, batch_size, log_dir, embedding_matrix)\u001b[0m\n\u001b[1;32m    101\u001b[0m         tr_loss, tr_acc = session.run([trainable.loss, trainable.accuracy],\n\u001b[1;32m    102\u001b[0m                                       feed_dict={trainable.X: train_data,\n\u001b[0;32m--> 103\u001b[0;31m                                                  trainable.Y: train_labels})\n\u001b[0m\u001b[1;32m    104\u001b[0m         \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0mtrain_accs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/Tensorflow/.pyenv/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/Tensorflow/.pyenv/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m                              \u001b[0;34m'which has shape %r'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m                              (np_val.shape, subfeed_t.name,\n\u001b[0;32m-> 1128\u001b[0;31m                               str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m   1129\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (2084, 16, 595) for Tensor 'data:0', which has shape '(?, 16)'"
     ]
    }
   ],
   "source": [
    "tr.train_model(rnn_words, data, labels, sampler, epochs=EPOCHS, batch_size=BATCH_SIZE, log_dir=\"logs/10-test-glove\")\n",
    "\n",
    "\"\"\"\n",
    "with tf.variable_scope(\"lstm\"):\n",
    "    # Define a function that gives the output in the right shape\n",
    "    def lstm_cell():\n",
    "        return tf.nn.rnn_cell.LSTMCell(hidden_layer_size, forget_bias=1.0)\n",
    "    cell = tf.contrib.rnn.MultiRNNCell(cells=[lstm_cell() for _ in range(num_LSTM_layers)],\n",
    "                                       state_is_tuple=True)\n",
    "    outputs, states = tf.nn.dynamic_rnn(cell, embed,\n",
    "                                        sequence_length=_seqlens,\n",
    "                                        dtype=tf.float32)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM phonem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"lstm_phonem\"):\n",
    "    # Define a function that gives the output in the right shape\n",
    "    def lstm_cell_phonem():\n",
    "        return tf.nn.rnn_cell.LSTMCell(hidden_layer_size_phonem, forget_bias=1.0)\n",
    "    cell_phonem = tf.contrib.rnn.MultiRNNCell(cells=[lstm_cell_phonem() for _ in range(num_LSTM_layers_phonem)],\n",
    "                                       state_is_tuple=True)\n",
    "    outputs_phonem, states_phonem = tf.nn.dynamic_rnn(cell_phonem, embed_phonem,\n",
    "                                        sequence_length=_seqlens_phonem,\n",
    "                                        dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
