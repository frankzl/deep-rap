{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06 - Embedded Multi Layer LSTM on our preprocessed text\n",
    "\n",
    "Let's feed the generated data from the previous notebook into our LSTM from chapter 4!\n",
    "\n",
    "This time we load our rap text from the **prepped** directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tools.architectures as nn\n",
    "import tools.processing as pre\n",
    "import tools.training as tr\n",
    "\n",
    "text = pre.get_text(\"data/prepped/clean2_pac.txt\")[:60000]\n",
    "vocab = pre.Vocabulary(text)\n",
    "\n",
    "text2 = pre.get_text(\"data/cleaned-rap-lyrics/clean2_pac_.txt\")[:60000]\n",
    "vocab2 = pre.Vocabulary(text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The prepared text should have reduced number of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size in prepped text: \t1938\n",
      "vocab size in previous text: \t2181\n"
     ]
    }
   ],
   "source": [
    "print( f\"vocab size in prepped text: \\t{len(vocab.index2word)}\")\n",
    "print( f\"vocab size in previous text: \\t{len(vocab2.index2word)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['as', 'real', 'as', 'it', 'seems', 'the', 'american', 'dream', ';', 'is', 'not', 'nothing', 'but', 'another', 'calculated', 'schemes', ';', 'to', 'get', 'us'], 'locked'), (['real', 'as', 'it', 'seems', 'the', 'american', 'dream', ';', 'is', 'not', 'nothing', 'but', 'another', 'calculated', 'schemes', ';', 'to', 'get', 'us', 'locked'], 'up'), (['as', 'it', 'seems', 'the', 'american', 'dream', ';', 'is', 'not', 'nothing', 'but', 'another', 'calculated', 'schemes', ';', 'to', 'get', 'us', 'locked', 'up'], 'shot'), (['it', 'seems', 'the', 'american', 'dream', ';', 'is', 'not', 'nothing', 'but', 'another', 'calculated', 'schemes', ';', 'to', 'get', 'us', 'locked', 'up', 'shot'], 'up'), (['seems', 'the', 'american', 'dream', ';', 'is', 'not', 'nothing', 'but', 'another', 'calculated', 'schemes', ';', 'to', 'get', 'us', 'locked', 'up', 'shot', 'up'], 'back')]\n"
     ]
    }
   ],
   "source": [
    "TIMESTEPS = 20\n",
    "\n",
    "vocab = pre.Vocabulary(text)\n",
    "\n",
    "tokens = text.split(\" \")[:-1]\n",
    "\n",
    "str_data, str_labels = pre.create_data_label_pairs(tokens, TIMESTEPS)\n",
    "\n",
    "print( list( zip(str_data, str_labels) )[:5] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = tr.IndexWordEncoder(\"Index-Word-Encoding\", vocab.word2index)\n",
    "decoder = tr.OneHotWordDecoder(\"1-Hot-Word-Decoding\", vocab.index2word, temperature=0.5)\n",
    "\n",
    "data = encoder.encode( str_data )\n",
    "labels = encoder.encode_labels( str_labels )\n",
    "\n",
    "my_seed = \" \".join(str_data[0]).replace(\"\\\\n\", \"\\n\")\n",
    "\n",
    "del str_data, str_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../logs/06/testing/model\n",
      "Restoring an old model from '../logs/06/testing' and training it further..\n",
      "\n",
      "\n",
      "Epoch 1/20\n",
      "Loss:    \t 3.2836549282073975\n",
      "Accuracy:\t 36.18242263793945\n",
      "------Sampling----------\n",
      "seed: \n",
      "as real as it seems the american dream ; is not nothing but another calculated schemes ; to get us\n",
      "-\n",
      "result: \n",
      "as real as it seems the american dream ; is not nothing but another calculated schemes ; to get us of the car i am rocking ; i am violent on the streets is a lesson ; so i am on the cop is not an understand ; and if i am the bullet of the type of the government ; but the clock is not the police in deep\n",
      "\n",
      "\n",
      "Epoch 2/20\n",
      "Loss:    \t 2.833693265914917\n",
      "Accuracy:\t 43.82361602783203\n",
      "------Sampling----------\n",
      "seed: \n",
      "as real as it seems the american dream ; is not nothing but another calculated schemes ; to get us\n",
      "-\n",
      "result: \n",
      "as real as it seems the american dream ; is not nothing but another calculated schemes ; to get us locked up shot up back in chains chains and we all the car to the other ; but we are not know they say that we are getting do not know they will be beat in a bitch ; aiyyo and then we will never be beat ; if you\n",
      "\n",
      "\n",
      "Epoch 3/20\n",
      "Loss:    \t 2.3381240367889404\n",
      "Accuracy:\t 50.762611389160156\n",
      "------Sampling----------\n",
      "seed: \n",
      "as real as it seems the american dream ; is not nothing but another calculated schemes ; to get us\n",
      "-\n",
      "result: \n",
      "as real as it seems the american dream ; is not nothing but another calculated schemes ; to get us locked up back in chains ; with the mic to get us him to the concrete ; they gave me a nigga ; i am coming to get whipped ; i am the cop of the government ; the nigga in the black youth ; the american dream nigga it\n",
      "\n",
      "\n",
      "Epoch 4/20\n",
      "Loss:    \t 1.9291739463806152\n",
      "Accuracy:\t 62.46601867675781\n",
      "------Sampling----------\n",
      "seed: \n",
      "as real as it seems the american dream ; is not nothing but another calculated schemes ; to get us\n",
      "-\n",
      "result: \n",
      "as real as it seems the american dream ; is not nothing but another calculated schemes ; to get us locked up up back in chains chains ; ay deny us of the car and i will be damned ; you are watching my at and i will find it ; i am taking to get whipped ; ya think its unbelievable ; but i am a soldier to get\n",
      "\n",
      "\n",
      "Epoch 5/20\n",
      "Loss:    \t 1.4888821840286255\n",
      "Accuracy:\t 71.84385681152344\n",
      "------Sampling----------\n",
      "seed: \n",
      "as real as it seems the american dream ; is not nothing but another calculated schemes ; to get us\n",
      "-\n",
      "result: \n",
      "as real as it seems the american dream ; is not nothing but another calculated schemes ; to get us up shot up back to the knot ; ya shot up and get dropped with ya posse ; nigga got the clock ; now i am smoking these niggas like they indo ; breaking me like they windows and still they with until ; until they get a whiff of\n",
      "\n",
      "\n",
      "Epoch 6/20\n",
      "Loss:    \t 1.1199215650558472\n",
      "Accuracy:\t 78.72244262695312\n",
      "------Sampling----------\n",
      "seed: \n",
      "as real as it seems the american dream ; is not nothing but another calculated schemes ; to get us\n",
      "-\n",
      "result: \n",
      "as real as it seems the american dream ; is not nothing but another calculated schemes ; to get us locked up up back in chains ; they shine of the future rob our patience ; you hear my one is in the life ; i am coming for the bastard you ; i get sweated my homie and i dropped all ; i gave you all the way to\n",
      "\n",
      "\n",
      "Epoch 7/20\n",
      "Loss:    \t 0.8310970664024353\n",
      "Accuracy:\t 85.66143035888672\n",
      "------Sampling----------\n",
      "seed: \n",
      "as real as it seems the american dream ; is not nothing but another calculated schemes ; to get us\n",
      "-\n",
      "result: \n",
      "as real as it seems the american dream ; is not nothing but another calculated schemes ; to get us locked up shot up back in chains ; to deny us of the future rob our names ; kept my history of mystery but now i see ; the american dream was not meant for me ; because lady liberty is a hypocrite she lied to me ; promised me\n",
      "\n",
      "\n",
      "Epoch 8/20\n",
      "Loss:    \t 0.6724535226821899\n",
      "Accuracy:\t 90.22199249267578\n",
      "------Sampling----------\n",
      "seed: \n",
      "as real as it seems the american dream ; is not nothing but another calculated schemes ; to get us\n",
      "-\n",
      "result: \n",
      "as real as it seems the american dream ; is not nothing but another calculated schemes ; to get us locked up shot up back in chains ; to deny us of the future rob our names ; kept my history of mystery but now i see ; the american dream was not meant for me ; because lady liberty is a hypocrite she lied to me ; promised me\n",
      "\n",
      "\n",
      "Epoch 9/20\n",
      "Loss:    \t 0.48683589696884155\n",
      "Accuracy:\t 94.07279205322266\n",
      "------Sampling----------\n",
      "seed: \n",
      "as real as it seems the american dream ; is not nothing but another calculated schemes ; to get us\n",
      "-\n",
      "result: \n",
      "as real as it seems the american dream ; is not nothing but another calculated schemes ; to get us locked up shot up back in chains ; to deny us of the future rob our names ; kept my history of mystery but now i see ; the american dream was not meant for me ; because lady liberty is a hypocrite she lied to me ; she had\n",
      "\n",
      "\n",
      "Epoch 10/20\n",
      "Loss:    \t 0.3620468080043793\n",
      "Accuracy:\t 96.7230453491211\n",
      "------Sampling----------\n",
      "seed: \n",
      "as real as it seems the american dream ; is not nothing but another calculated schemes ; to get us\n",
      "-\n",
      "result: \n",
      "as real as it seems the american dream ; is not nothing but another calculated schemes ; to get us locked up shot up back in chains ; to deny us of the future rob our names ; kept my history of mystery but now i see ; the american dream was not meant for me ; because lady liberty is a hypocrite she lied to me ; promised me\n",
      "\n",
      "\n",
      "Epoch 11/20\n",
      "Loss:    \t 0.28673407435417175\n",
      "Accuracy:\t 97.59890747070312\n",
      "------Sampling----------\n",
      "seed: \n",
      "as real as it seems the american dream ; is not nothing but another calculated schemes ; to get us\n",
      "-\n",
      "result: \n",
      "as real as it seems the american dream ; is not nothing but another calculated schemes ; to get us locked up shot up back in chains ; to deny us of the future rob our names ; kept my history of mystery but now i see ; the american dream was not meant for me ; because lady liberty is a hypocrite she lied to me ; promised me\n",
      "\n",
      "\n",
      "Epoch 12/20\n",
      "Loss:    \t 0.24069996178150177\n",
      "Accuracy:\t 97.93113708496094\n",
      "------Sampling----------\n",
      "seed: \n",
      "as real as it seems the american dream ; is not nothing but another calculated schemes ; to get us\n",
      "-\n",
      "result: \n",
      "as real as it seems the american dream ; is not nothing but another calculated schemes ; to get us locked up shot up back in chains ; to deny us of the future rob our names ; kept my history of mystery but now i see ; the american dream was not meant for me ; because lady liberty is a hypocrite she lied to me ; promised me\n",
      "\n",
      "\n",
      "Epoch 13/20\n",
      "Loss:    \t 0.2085244506597519\n",
      "Accuracy:\t 98.26336669921875\n",
      "------Sampling----------\n",
      "seed: \n",
      "as real as it seems the american dream ; is not nothing but another calculated schemes ; to get us\n",
      "-\n",
      "result: \n",
      "as real as it seems the american dream ; is not nothing but another calculated schemes ; to get us locked up shot up back in chains ; to deny us of the future rob our names ; kept my history of mystery but now i see ; the american dream was not meant for me ; because lady liberty is a hypocrite she lied to me ; promised me\n",
      "\n",
      "\n",
      "Epoch 14/20\n",
      "Loss:    \t 0.1797558218240738\n",
      "Accuracy:\t 98.36151885986328\n",
      "------Sampling----------\n",
      "seed: \n",
      "as real as it seems the american dream ; is not nothing but another calculated schemes ; to get us\n",
      "-\n",
      "result: \n",
      "as real as it seems the american dream ; is not nothing but another calculated schemes ; to get us locked up shot up back in chains ; to deny us of the future rob our names ; kept my history of mystery but now i see ; the american dream was not meant for me ; because lady liberty is a hypocrite she lied to me ; promised me\n",
      "\n",
      "\n",
      "Epoch 15/20\n",
      "Loss:    \t 0.16597090661525726\n",
      "Accuracy:\t 98.42947387695312\n",
      "------Sampling----------\n",
      "seed: \n",
      "as real as it seems the american dream ; is not nothing but another calculated schemes ; to get us\n",
      "-\n",
      "result: \n",
      "as real as it seems the american dream ; is not nothing but another calculated schemes ; to get us locked up shot up back in chains ; to deny us of the future rob our names ; kept my history of mystery but now i see ; the american dream was not meant for me ; because lady liberty is a hypocrite she lied to me ; promised me\n",
      "\n",
      "\n",
      "Epoch 16/20\n",
      "Loss:    \t 0.1557893455028534\n",
      "Accuracy:\t 98.48233032226562\n",
      "------Sampling----------\n",
      "seed: \n",
      "as real as it seems the american dream ; is not nothing but another calculated schemes ; to get us\n",
      "-\n",
      "result: \n",
      "as real as it seems the american dream ; is not nothing but another calculated schemes ; to get us locked up shot up back in chains ; to deny us of the future rob our names ; kept my history of mystery but now i see ; the american dream was not meant for me ; because lady liberty is a hypocrite she lied to me ; promised me\n",
      "\n",
      "\n",
      "Epoch 17/20\n",
      "Loss:    \t 0.14960451424121857\n",
      "Accuracy:\t 98.56538391113281\n",
      "------Sampling----------\n",
      "seed: \n",
      "as real as it seems the american dream ; is not nothing but another calculated schemes ; to get us\n",
      "-\n",
      "result: \n",
      "as real as it seems the american dream ; is not nothing but another calculated schemes ; to get us locked up shot up back in chains ; to deny us of the future rob our names ; kept my history of mystery but now i see ; the american dream was not meant for me ; because lady liberty is a hypocrite she lied to me ; promised me\n",
      "\n",
      "\n",
      "Epoch 18/20\n",
      "Loss:    \t 0.14553692936897278\n",
      "Accuracy:\t 98.58049011230469\n",
      "------Sampling----------\n",
      "seed: \n",
      "as real as it seems the american dream ; is not nothing but another calculated schemes ; to get us\n",
      "-\n",
      "result: \n",
      "as real as it seems the american dream ; is not nothing but another calculated schemes ; to get us locked up shot up back in chains ; to deny us of the future rob our names ; kept my history of mystery but now i see ; the american dream was not meant for me ; because lady liberty is a hypocrite she lied to me ; promised me\n",
      "\n",
      "\n",
      "Epoch 19/20\n",
      "Loss:    \t 0.1431473046541214\n",
      "Accuracy:\t 98.6106948852539\n",
      "------Sampling----------\n",
      "seed: \n",
      "as real as it seems the american dream ; is not nothing but another calculated schemes ; to get us\n",
      "-\n",
      "result: \n",
      "as real as it seems the american dream ; is not nothing but another calculated schemes ; to get us locked up shot up back in chains ; to deny us of the future rob our names ; kept my history of mystery but now i see ; the american dream was not meant for me ; because lady liberty is a hypocrite she lied to me ; promised me\n",
      "\n",
      "\n",
      "Epoch 20/20\n",
      "Loss:    \t 0.14172761142253876\n",
      "Accuracy:\t 98.60314178466797\n",
      "------Sampling----------\n",
      "seed: \n",
      "as real as it seems the american dream ; is not nothing but another calculated schemes ; to get us\n",
      "-\n",
      "result: \n",
      "as real as it seems the american dream ; is not nothing but another calculated schemes ; to get us locked up shot up back in chains ; to deny us of the future rob our names ; kept my history of mystery but now i see ; the american dream was not meant for me ; because lady liberty is a hypocrite she lied to me ; promised me\n"
     ]
    }
   ],
   "source": [
    "HIDDEN_LAYER_SIZE = 512\n",
    "VOCAB_SIZE = len(vocab.word2index)\n",
    "\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "EMBEDDING_SIZE = 256\n",
    "\n",
    "rnn = nn.EmbeddedSingleLayerRNN(name = \"multi-2pac\")\n",
    "rnn.build(HIDDEN_LAYER_SIZE, VOCAB_SIZE, EMBEDDING_SIZE, TIMESTEPS, l2_reg=0.0)\n",
    "\n",
    "sampler = lambda trainable, _: tr.sample( my_seed, trainable, encoder, decoder, length=50)\n",
    "\n",
    "tr.train_model(rnn, data, labels, sampler, epochs=EPOCHS, batch_size=BATCH_SIZE, log_dir=\"logs/06/testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Sampling----------\n",
      "seed: \n",
      "when i was thirteen ; i had my first love ; there was nobody that could put hands on my baby ; and nobody came between us that could ever come above\n",
      "-\n",
      "result: \n",
      "when i was thirteen ; i had my first love ; there was nobody that could put hands on my baby ; and nobody came between us that could ever come above ; i said you are confident my i dropped ; i would not fighting all that i could not be ; you to be a soulja like me ; all you wanted to be a soulja a soulja ; all you wanted to be a soulja like me ; ;\n"
     ]
    }
   ],
   "source": [
    "decoder.temperature = 0.8\n",
    "\n",
    "sampler = lambda seed_text: tr.sample( seed_text, rnn, encoder, decoder, length=50)\n",
    "\n",
    "sampler(\"when i was thirteen ; i had my first love ; there was nobody that could put hands on my baby ; and nobody came between us that could ever come above\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------\n",
    "\n",
    "\n",
    "### Let's try a different rapper this time: Rakim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yeah you know what this is nyc ; the triumphant return rakim allah ; rakim ; remember being introduced to'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TIMESTEPS = 20\n",
    "\n",
    "text = pre.get_text(\"data/prepped/cleanrakim.txt\")[:60000]\n",
    "\n",
    "vocab = pre.Vocabulary(text)\n",
    "\n",
    "tokens = text.split(\" \")[:-1]\n",
    "\n",
    "str_data, str_labels = pre.create_data_label_pairs(tokens, TIMESTEPS)\n",
    "\n",
    "my_seed = \" \".join(str_data[0])\n",
    "my_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "At least two variables have the same name: Variable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-d2f65073ef7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mmy_seed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mtr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"logs/06/testing\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/coding/deep-rap/tools/training.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(trainable, train_data, train_labels, sampler, epochs, batch_size, log_dir, embedding_matrix)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0msaver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_to_keep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_checkpoint_every_n_hours\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.envs/env36-ml/.venv/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, var_list, reshape, sharded, max_to_keep, keep_checkpoint_every_n_hours, name, restore_sequentially, saver_def, builder, defer_build, allow_empty, write_version, pad_step_number, save_relative_paths, filename)\u001b[0m\n\u001b[1;32m   1100\u001b[0m           time.time() + self._keep_checkpoint_every_n_hours * 3600)\n\u001b[1;32m   1101\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdefer_build\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1102\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaver_def\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_saver_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.envs/env36-ml/.venv/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Use save/restore instead of build in eager mode.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_save\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_restore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_build_eager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_save\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_restore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.envs/env36-ml/.venv/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36m_build\u001b[0;34m(self, checkpoint_path, build_save, build_restore)\u001b[0m\n\u001b[1;32m   1149\u001b[0m           \u001b[0mrestore_sequentially\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_restore_sequentially\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m           \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m           build_save=build_save, build_restore=build_restore)\n\u001b[0m\u001b[1;32m   1152\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaver_def\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m       \u001b[0;31m# Since self._name is used as a name_scope by builder(), we are\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.envs/env36-ml/.venv/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36m_build_internal\u001b[0;34m(self, names_to_saveables, reshape, sharded, max_to_keep, keep_checkpoint_every_n_hours, name, restore_sequentially, filename, build_save, build_restore)\u001b[0m\n\u001b[1;32m    771\u001b[0m                        \" when eager execution is not enabled.\")\n\u001b[1;32m    772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 773\u001b[0;31m     \u001b[0msaveables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ValidateAndSliceInputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames_to_saveables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    774\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmax_to_keep\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m       \u001b[0mmax_to_keep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.envs/env36-ml/.venv/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36m_ValidateAndSliceInputs\u001b[0;34m(self, names_to_saveables)\u001b[0m\n\u001b[1;32m    671\u001b[0m     \"\"\"\n\u001b[1;32m    672\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames_to_saveables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m       \u001b[0mnames_to_saveables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBaseSaverBuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpListToDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames_to_saveables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0msaveables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.envs/env36-ml/.venv/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mOpListToDict\u001b[0;34m(op_list, convert_variable_to_tensor)\u001b[0m\n\u001b[1;32m    570\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnames_to_saveables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m             raise ValueError(\"At least two variables have the same name: %s\" %\n\u001b[0;32m--> 572\u001b[0;31m                              name)\n\u001b[0m\u001b[1;32m    573\u001b[0m           \u001b[0mnames_to_saveables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: At least two variables have the same name: Variable"
     ]
    }
   ],
   "source": [
    "NUM_LAYERS = 2\n",
    "HIDDEN_LAYER_SIZE = 256\n",
    "VOCAB_SIZE = vocab.get_size()\n",
    "\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "EMBEDDING_SIZE = 256\n",
    "\n",
    "rnn = nn.EmbeddedMultiLayerRNN(name = \"multi-rakims\")\n",
    "rnn.build(NUM_LAYERS, HIDDEN_LAYER_SIZE, VOCAB_SIZE, EMBEDDING_SIZE, TIMESTEPS, l2_reg=0.0)\n",
    "\n",
    "sampler = lambda trainable, _: tr.sample( my_seed, trainable, encoder, decoder, length=50)\n",
    "\n",
    "tr.train_model(rnn, data, labels, sampler, epochs=EPOCHS, batch_size=BATCH_SIZE, log_dir=\"logs/06/testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch 1/20\n",
      "Loss:    \t 6.085999488830566\n",
      "Accuracy:\t 9.765625\n",
      "as real as it seems the american dream\n",
      "is not nothing but another calculated schemes\n",
      "to get us\n",
      "Seed:as real as it seems the american dream \n",
      " is not nothing but another calculated schemes \n",
      " to get us \n",
      "Result:as real as it seems the american dream \n",
      " is not nothing but another calculated schemes \n",
      " to get us \n",
      " to tell \n",
      " facts \n",
      " i on \n",
      " only i \n",
      " the \n",
      " hipshot what you \n",
      " keep \n",
      " and \n",
      " you i get \n",
      " \n",
      " be \n",
      " \n",
      " the get \n",
      " shot to \n",
      " \n",
      " and a sexing at me \n",
      " be see i \n",
      " your \n",
      " the \n",
      " i motherfucker i am \n",
      " do me got \n",
      " \n",
      " the da me got \n",
      " kind i  \n",
      " fuck the to \n",
      " \n",
      " of piles \n",
      " the \n",
      " i the \n",
      " the \n",
      " all i the or the is now \n",
      " the \n",
      " in but i or i i and \n",
      " \n",
      " i got my and \n",
      " \n",
      " \n",
      " i \n",
      " is is \n",
      " tear \n",
      " the \n",
      " that is \n",
      " the still i little \n",
      " damn \n",
      " he to you \n",
      " a i he to \n",
      " real is the \n",
      " is \n",
      " \n",
      " \n",
      " his they of \n",
      " stepped winners \n",
      " made be obvious or i see \n",
      " i is my the heavily \n",
      " \n",
      " \n",
      " i of wanna brothers i the to man \n",
      " be the \n",
      " is \n",
      " \n",
      " is is the \n",
      " a i \n",
      " the on and not \n",
      " and on here \n",
      " stacks i when \n",
      " to \n",
      " \n",
      " \n",
      " is \n",
      " \n",
      " i to better \n",
      " \n",
      " we me to word \n",
      " that made \n",
      " \n",
      " i is \n",
      " you and i turned and the \n",
      " to i be \n",
      " i in i \n",
      " it is \n",
      " \n",
      " i \n",
      " the \n",
      " \n",
      " not \n",
      " you how to \n",
      " not she \n",
      " into not \n",
      " i the thought a \n",
      " we \n",
      " \n",
      " i they \n",
      " i is but \n",
      " \n",
      " to the i the \n",
      " this like \n",
      " \n",
      " i is asking the \n",
      " i the sees was the \n",
      " to i is and \n",
      " \n",
      " the \n",
      " is the is is is the is \n",
      " i a of i the up the \n",
      " the me the \n",
      " i we \n",
      " on \n",
      " god the to in can would \n",
      " the all more niggas \n",
      " \n",
      " you he to will or i little to \n",
      " \n",
      " but i \n",
      " brother \n",
      " to they say \n",
      " and and is \n",
      " \n",
      " put and \n",
      " paid \n",
      " \n",
      " hyson that of \n",
      " and be selling me i \n",
      " \n",
      " get i \n",
      " not \n",
      " i i this \n",
      " and is \n",
      " not in \n",
      " begins the not \n",
      " \n",
      " not i i is \n",
      " that is \n",
      " \n",
      " i is \n",
      " know know and come \n",
      " the to \n",
      " the of \n",
      " not am \n",
      " to \n",
      " daily we a \n",
      " got \n",
      " i the \n",
      " i and \n",
      " we to \n",
      " \n",
      " when would the \n",
      " disturbing \n",
      " \n",
      " defeat and \n",
      " the i \n",
      " my is \n",
      " to the that \n",
      " the the they just cause \n",
      " the tried \n",
      " the the the is \n",
      " the \n",
      " \n",
      " balls to make i the i is me they of can i \n",
      "\n",
      "\n",
      "Epoch 2/20\n",
      "Loss:    \t 5.819359302520752\n",
      "Accuracy:\t 12.890625\n",
      "as real as it seems the american dream\n",
      "is not nothing but another calculated schemes\n",
      "to get us\n",
      "Seed:as real as it seems the american dream \n",
      " is not nothing but another calculated schemes \n",
      " to get us \n",
      "Result:as real as it seems the american dream \n",
      " is not nothing but another calculated schemes \n",
      " to get us am a not \n",
      " i ass will the the \n",
      " i oh a hear the \n",
      " here is \n",
      " beat am i the the one me fucking \n",
      " i is the me \n",
      " i the some and you i hoods am \n",
      " i me the thing the \n",
      " with you just to \n",
      " another i to because \n",
      " is dream they my i micas 2 \n",
      " the is the shit and the but \n",
      " and you you and \n",
      " i down the cause that the to \n",
      " i me to to i to \n",
      " i in i a they \n",
      " i we get \n",
      " he \n",
      " more every is the the the with \n",
      " the nigga is \n",
      " and out is the the and \n",
      " my are is a i the the the heart \n",
      " a do the crime you to \n",
      " us now to the not am the me \n",
      " and a i \n",
      " the criminal so rock \n",
      " the each the the and is let \n",
      " and the the is is the that \n",
      " over the one i day \n",
      " tell am is to you \n",
      " the before to the down \n",
      " the a do to \n",
      " he a is all the to \n",
      " i the they is that \n",
      " to my the got \n",
      " and i as the a \n",
      " i the the got it to \n",
      " to i in am a ghettos \n",
      " the the the they we of \n",
      " the this rip a lied \n",
      " i sold got the \n",
      " i the nigga with the that a \n",
      " gotta the the you \n",
      " i is the the on the what to nigga \n",
      " \n",
      " i in and i they \n",
      " of the on and \n",
      " the now suddenly to the or \n",
      " i and the ya did da \n",
      " i to the that \n",
      " i let is a rougher \n",
      " i the me \n",
      " to they the a there to do \n",
      " i pac the \n",
      " is you a \n",
      " the a shit an on \n",
      " this of so the we you be \n",
      " the is they is is the was \n",
      " the now the is the the and is \n",
      " the the i the a i to a 2 \n",
      " i to the go of \n",
      " a is the trapped got i a \n",
      " is is could the the i \n",
      " i i motherfucker that \n",
      " i got is \n",
      " if young what the on and that is the way \n",
      " i am me cause the at \n",
      " but heart the got be beat in \n",
      " the the criminal and the clocking not \n",
      " a and they to my \n",
      " i how you keep blast \n",
      " and a the eye the in only \n",
      " not and the the the \n",
      " the with that you confident i is \n",
      " the this fuck \n",
      " i is from the ay do not \n",
      " the payen of tried a \n",
      " they not is \n",
      " a then the in \n",
      "\n",
      "\n",
      "Epoch 3/20\n",
      "Loss:    \t 5.627079963684082\n",
      "Accuracy:\t 16.796875\n",
      "as real as it seems the american dream\n",
      "is not nothing but another calculated schemes\n",
      "to get us\n",
      "Seed:as real as it seems the american dream \n",
      " is not nothing but another calculated schemes \n",
      " to get us \n",
      "Result:as real as it seems the american dream \n",
      " is not nothing but another calculated schemes \n",
      " to get us a your i a need of sweaty \n",
      " i am is the dream me to and the or \n",
      " do i am did and battle of say \n",
      " i and not a walked \n",
      " pac to the one i am me \n",
      " i is what the dope a streets \n",
      " i am nigga shot now to am in \n",
      " they my me to the is \n",
      " the coppers and like and and got the with the \n",
      " i am you to shot \n",
      " i to the sucker the freeze \n",
      " i i am out you not \n",
      " the not got on he did \n",
      " they up let \n",
      " you you act of of had \n",
      " i am the fuck the all the balling you run \n",
      " my you black gets rap \n",
      " i am am i can \n",
      " ya made not the and nigga the cannot in \n",
      " i the door to am be in the true \n",
      " i am these the \n",
      " i nigga is the fuck \n",
      " i am would the ears a that the uprise \n",
      " and the burnie \n",
      " who i am and get and come but the \n",
      " i am the way \n",
      " i am the in the and not this \n",
      " they the hate game i the hands \n",
      " the dj with the the up not up \n",
      " i am you is in the be \n",
      " the case dope it i case the never \n",
      " i the will ya i am on the than \n",
      " and fuck the gift the am seems the habit the in \n",
      " i am is not am for how is all nilgau \n",
      " i am to do and the swell \n",
      " are me \n",
      " i am do a say nine \n",
      " i am me the though \n",
      " they the kicking to are the girl \n",
      " i they a shit i the meant the is that the motts \n",
      " the why than is the god not ever racist \n",
      " got i am \n",
      " i am cops just \n",
      " i am is one he the am the bein \n",
      " all the is they a shot \n",
      " he this \n",
      " they my to will to \n",
      " i am the get so the it \n",
      " the fuck i am the car \n",
      " all i my a one addicts \n",
      " about the is nilgau \n",
      " they for the by the time the open holies \n",
      " i am got the nightstand lies that the sat \n",
      " i am someone is it the us \n",
      " you ass my his the cause \n",
      " they the to the aim \n",
      " the scary me reads the again \n",
      " i you of on to what my the know \n",
      " i am with in the a real is the young \n",
      " you her the bit \n",
      " criminal what is we rip through \n",
      " i am up got the a in \n",
      " and the i am did the of the it \n",
      " i am up and chorus i the vicious \n",
      " i \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-53ff8c56f46b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_LAYERS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHIDDEN_LAYER_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVOCAB_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTIMESTEPS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml2_reg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/coding/deep-rap/tools/architectures.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(trainable, train_data, train_labels, alphabet, epochs, batch_size, temperature, embedding)\u001b[0m\n\u001b[1;32m     51\u001b[0m                         feed_dict={\n\u001b[1;32m     52\u001b[0m                             \u001b[0mtrainable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_ixs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m                             \u001b[0mtrainable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_ixs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m                             })\n\u001b[1;32m     55\u001b[0m                 \u001b[0mloss_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtr_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.envs/env36-ml/.venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.envs/env36-ml/.venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.envs/env36-ml/.venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.envs/env36-ml/.venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.envs/env36-ml/.venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.envs/env36-ml/.venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tools.architectures as nn\n",
    "import tools.processing as pre\n",
    "\n",
    "text = pre.get_text(\"data/prepped/clean2_pac.txt\")[:60000]\n",
    "vocab = pre.Vocabulary(text)\n",
    "\n",
    "#print(corrected.replace(\" lbreak \", \"\\n\"))\n",
    "# processed\n",
    "# text = corrected.replace(\" lbreak \", \"\\n\")\n",
    "\n",
    "NUM_LAYERS = 2\n",
    "HIDDEN_LAYER_SIZE = 256\n",
    "VOCAB_SIZE = vocab.get_size()\n",
    "TIMESTEPS = 20\n",
    "\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "EMBEDDING_SIZE = 128\n",
    "\n",
    "\n",
    "data, labels = vocab.making_embedded_one_hot(text, TIMESTEPS)\n",
    "\n",
    "embedding = nn.LeanableEmbedding(name = \"learnable-embedding-2\")\n",
    "embedding.build(VOCAB_SIZE, EMBEDDING_SIZE)\n",
    "\n",
    "rnn = nn.MultiLayerRNN(name = \"multi-pac-total\")\n",
    "rnn.build(NUM_LAYERS, HIDDEN_LAYER_SIZE, VOCAB_SIZE, TIMESTEPS, l2_reg=0.0, embedding=embedding)\n",
    "\n",
    "nn.train(rnn, data, labels, vocab, epochs=EPOCHS, batch_size=BATCH_SIZE, temperature=.6, embedding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
