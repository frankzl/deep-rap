{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import cmudict as cmu\n",
    "\n",
    "entries = cmu.entries()\n",
    "arpabet = cmu.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown_words = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_phonem(text):\n",
    "    try:\n",
    "        return arpabet[text][0]\n",
    "    except:\n",
    "        unknown_words.add(text)\n",
    "        return text\n",
    "\n",
    "def get_phonem_string(text):\n",
    "    try:\n",
    "        return \"\".join(arpabet[text][0])\n",
    "    except:\n",
    "        unknown_words.add(text)\n",
    "        return \"\"\n",
    "\n",
    "def get_phonem_string_spaced(text):\n",
    "    try:\n",
    "        return \" \".join(arpabet[text][0])\n",
    "    except:\n",
    "        unknown_words.add(text)\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"entry #50:\", entries[50])\n",
    "print()\n",
    "# show entries for \"hello\"\n",
    "for entry in entries:\n",
    "    if entry[0] == \"hello\":\n",
    "        print(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"dream\"\n",
    "print(text, \" --> \", get_phonem(text))\n",
    "print(text, \" --> \", get_phonem_string(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = \"scheme\"\n",
    "print(text2, \" --> \", get_phonem(text2))\n",
    "print(text2, \" --> \", get_phonem_string(text2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get ryhme for word\n",
    "# level represents accuracy of rhyme: take the last {level} phonems to compare\n",
    "def rhyme(inp, level):\n",
    "    syllables = [(word, syl) for word, syl in entries if word == inp]\n",
    "    rhymes = []\n",
    "    for (word, syllable) in syllables:\n",
    "        rhymes += [word for word, pron in entries if pron[-level:] == syllable[-level:]]\n",
    "    return list(set(rhymes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"dream\" in rhyme(\"scheme\", 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pronouncing\n",
    "pronouncing.rhymes(\"scheme\")[12:20]\n",
    "#pronouncing.phones_for_word(\"scheme\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process rap lyrics to phonems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'as real as it seems the american dream ; is not nothing but another calculated schemes ; to get us l'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tools.processing as pre\n",
    "text_2pac = pre.get_text(\"data/cleaned-rap-lyrics/clean2_pac.txt\")\n",
    "text_kidcudi = pre.get_text(\"data/cleaned-rap-lyrics/cleankid_cudi.txt\")\n",
    "text_rakim = pre.get_text(\"data/cleaned-rap-lyrics/cleanrakim.txt\")\n",
    "text_2pac[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize cleaned text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_wt = nltk.word_tokenize\n",
    "words_2pac = default_wt(text_2pac)\n",
    "words_kidcudi = default_wt(text_kidcudi)\n",
    "words_rakim = default_wt(text_rakim)\n",
    "len(words_2pac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(words_2pac[:9])\n",
    "print(words_kidcudi[:9])\n",
    "print(words_rakim[:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in words_2pac[:17]:\n",
    "    print(word, \"\\t\", get_phonem_string(word), \"\\t\", get_phonem_string_spaced(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfer text to phonetics-text\n",
    "# 2pac\n",
    "phonem_text = (\" \").join([get_phonem_string(word) for word in words_2pac]) \n",
    "phonem_2pac = (\" \").join([get_phonem_string_spaced(word) for word in words_2pac]) \n",
    "\n",
    "phonem_kidcudi = (\" \").join([get_phonem_string_spaced(word) for word in words_kidcudi]) \n",
    "phonem_rakim = (\" \").join([get_phonem_string_spaced(word) for word in words_rakim]) \n",
    "\n",
    "phonem_words = default_wt(phonem_text)\n",
    "print(phonem_words[:9])    \n",
    "\n",
    "phonem_words_spaced = default_wt(phonem_2pac)\n",
    "print(phonem_words_spaced[:9])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(unknown_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(unknown_words) > 0:\n",
    "    unknown_words_list = \"\\n\".join(list(unknown_words))\n",
    "    print(unknown_words_list)\n",
    "    pre.write_text(\"data/cleaned-rap-lyrics/unknown_words.txt\", unknown_words_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dict form unknown words\n",
    "unknown_dict = {}\n",
    "unknown_list = pre.get_text(\"data/cleaned-rap-lyrics/unknown_words_dict.txt\")\n",
    "splits = unknown_list.split(\"\\n\")\n",
    "for split in splits:\n",
    "    try:\n",
    "        word, phonem = split.split(\":\")\n",
    "    except:\n",
    "        print(split)\n",
    "    unknown_dict[word.lower()] = [phonem.split(\" \")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(arpabet))\n",
    "print(len(unknown_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge both dictionaries \n",
    "arpabet = {**arpabet, **unknown_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving in file\n",
    "#pre.write_text(\"data/phonem-rap-lyrics/phonem_2pac.txt\", phonem_2pac)\n",
    "#pre.write_text(\"data/phonem-rap-lyrics/phonem_kidcudi.txt\", phonem_kidcudi)\n",
    "#pre.write_text(\"data/phonem-rap-lyrics/phonem_rakim.txt\", phonem_rakim)\n",
    "#pre.write_text(\"data/phonem-rap-lyrics/phonem_all3.txt\", phonem_2pac + phonem_kidcudi + phonem_rakim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer findings into own library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tools.phonetics as phon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['L', 'AY1', 'B', 'R', 'EH2', 'R', 'IY0']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phon.get_phonem(\"library\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['library', 'arbitrary']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phon.rhyme(\"library\", 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#create own rhyme dict\n",
    "#for word in sorted(list(set(arpabet))):\n",
    "count = 0\n",
    "for word in (arpabet):\n",
    "    if len(nltk.corpus.wordnet.synsets(word)) > 1:\n",
    "        print(word, phon.rhyme(word, 2)[:10])\n",
    "        print()\n",
    "        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cleaned text combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#unknown: 1410\n",
      "\n",
      "#unknown: 0\n"
     ]
    }
   ],
   "source": [
    "cleaned_rap_lyrics = pre.get_text(\"data/cleaned-rap-lyrics/ref_text3.txt\")\n",
    "phonem_all = phon.text_to_phonem(cleaned_rap_lyrics)\n",
    "\n",
    "unknown_words = phon.get_unknown_words()\n",
    "print(\"#unknown:\", len(unknown_words))\n",
    "\n",
    "if len(unknown_words) > 0:\n",
    "    # use logios lextool to get generated phonetics from unknown\n",
    "    # http://www.speech.cs.cmu.edu/tools/lextool.html\n",
    "    unknown_list = pre.get_text(\"data/cleaned-rap-lyrics/unknown_words_dict.txt\")\n",
    "    unknown_dict = phon.create_unknown_dict_from_text(unknown_list)\n",
    "\n",
    "    phon.update_arpabet(unknown_dict)\n",
    "\n",
    "    phonem_all = phon.text_to_phonem(cleaned_rap_lyrics) \n",
    "    unknown_words = phon.get_unknown_words()\n",
    "    print(\"#unknown:\", len(unknown_words))\n",
    "\n",
    "pre.write_text(\"data/phonem-rap-lyrics/phonem_all.txt\", phonem_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
